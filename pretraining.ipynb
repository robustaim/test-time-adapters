{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training with SHIFT-Discrete Dataset (Clear-Daytime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Configs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "from os import path, environ\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "\n",
    "from ttadapters import datasets, models\n",
    "from ttadapters.utils import visualizer, validator\n",
    "from ttadapters.datasets import DatasetHolder, scenarios, SHIFTDataset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "environ[\"TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS\"] = \"1\"\n",
    "environ[\"TORCHDYNAMO_CAPTURE_DYNAMIC_OUTPUT_SHAPE_OPS\"] = \"1\"\n",
    "\n",
    "torch._dynamo.config.capture_scalar_outputs = True\n",
    "torch._dynamo.config.suppress_errors = True"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Arguments"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set Batch Size\n",
    "BATCH_SIZE = 2, 8, 1  # Local\n",
    "#BATCH_SIZE = 40, 200, 1  # A100 or H100\n",
    "ACCUMULATE_STEPS = 1\n",
    "\n",
    "# Set Data Root\n",
    "DATA_ROOT = path.join(\".\", \"data\")\n",
    "\n",
    "# Set Target Dataset\n",
    "SOURCE_DOMAIN = datasets.SHIFTDataset\n",
    "\n",
    "# Set Run Mode\n",
    "TEST_MODE = False\n",
    "\n",
    "# Set Model List\n",
    "MODEL_ZOO = [\"rcnn\", \"swinrcnn\", \"yolo11\", \"rtdetr\"]\n",
    "MODEL_TYPE = MODEL_ZOO[-1]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create argument parser\n",
    "parser = ArgumentParser(description=\"Training script for Test-Time Adapters\")\n",
    "\n",
    "# Add model arguments\n",
    "parser.add_argument(\"--dataset\", type=str, choices=[\"shift\", \"city\"], default=\"shift\", help=\"Training dataset\")\n",
    "parser.add_argument(\"--model\", type=str, choices=MODEL_ZOO, default=MODEL_TYPE, help=\"Model architecture\")\n",
    "\n",
    "# Add training arguments\n",
    "parser.add_argument(\"--train-batch\", type=int, default=BATCH_SIZE[0], help=\"Training batch size\")\n",
    "parser.add_argument(\"--valid-batch\", type=int, default=BATCH_SIZE[1], help=\"Validation batch size\")\n",
    "parser.add_argument(\"--accum-step\", type=int, default=ACCUMULATE_STEPS, help=\"Gradient accumulation steps\")\n",
    "parser.add_argument(\"--data-root\", type=str, default=DATA_ROOT, help=\"Root directory for datasets\")\n",
    "parser.add_argument(\"--device\", type=int, default=0, help=\"CUDA device number\")\n",
    "parser.add_argument(\"--additional_gpu\", type=int, default=0, help=\"Additional CUDA device count\")\n",
    "parser.add_argument(\"--use-bf16\", action=\"store_true\", help=\"Use bfloat16 precision\")\n",
    "parser.add_argument(\"--test-only\", action=\"store_true\", help=\"Run in test-only mode\")\n",
    "\n",
    "# Parsing arguments\n",
    "if \"ipykernel\" in sys.modules:\n",
    "    args = parser.parse_args([\"--test-only\"] if TEST_MODE else [])\n",
    "    print(\"INFO: Running in notebook mode with default arguments\")\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# Update global variables based on parsed arguments\n",
    "BATCH_SIZE = args.train_batch, args.valid_batch, BATCH_SIZE[2]\n",
    "ACCUMULATE_STEPS = args.accum_step\n",
    "DATA_ROOT = args.data_root\n",
    "TEST_MODE = args.test_only\n",
    "MODEL_TYPE = args.model\n",
    "match args.dataset:\n",
    "    case \"shift\":\n",
    "        SOURCE_DOMAIN = datasets.SHIFTDataset\n",
    "    case \"city\":\n",
    "        SOURCE_DOMAIN = datasets.CityScapesDataset\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported dataset: {args.dataset}\")\n",
    "print(f\"INFO: Set batch size - Train: {BATCH_SIZE[0]}, Valid: {BATCH_SIZE[1]}, Test: {BATCH_SIZE[2]}\")\n",
    "print(f\"INFO: Set test mode - {TEST_MODE} for {SOURCE_DOMAIN.dataset_name} dataset\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!nvidia-smi"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set CUDA Device Number\n",
    "DEVICE_NUM = 0 if not args.device else args.device\n",
    "ADDITIONAL_GPU = 0 if not args.additional_gpu else args.additional_gpu\n",
    "DATA_TYPE = torch.float32 if not args.use_bf16 else torch.bfloat16\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if ADDITIONAL_GPU:\n",
    "        torch.cuda.set_device(DEVICE_NUM)\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{DEVICE_NUM}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DEVICE_NUM = -1\n",
    "\n",
    "print(f\"INFO: Using device - {device}\" + (f\":{DEVICE_NUM}\" if ADDITIONAL_GPU else \"\"))\n",
    "print(f\"INFO: Using data precision - {DATA_TYPE}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Fast download patch\n",
    "datasets.patch_fast_download_for_object_detection()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Basic pre-training dataset\n",
    "match SOURCE_DOMAIN:\n",
    "    case datasets.SHIFTDataset:\n",
    "        discrete_dataset = DatasetHolder(\n",
    "            train=datasets.SHIFTClearDatasetForObjectDetection(root=DATA_ROOT, train=True),\n",
    "            valid=datasets.SHIFTClearDatasetForObjectDetection(root=DATA_ROOT, valid=True),\n",
    "            test=datasets.SHIFTCorruptedDatasetForObjectDetection(root=DATA_ROOT, valid=True)\n",
    "        )\n",
    "        continuous_dataset = DatasetHolder(\n",
    "            train=datasets.SHIFTContinuous100DatasetForObjectDetection(root=DATA_ROOT),\n",
    "            valid=datasets.SHIFTContinuous10DatasetForObjectDetection(root=DATA_ROOT),\n",
    "            test=datasets.SHIFTContinuousSubsetForObjectDetection(root=DATA_ROOT)\n",
    "        )\n",
    "        dataset = discrete_dataset\n",
    "    case datasets.CityScapesDataset:\n",
    "        discrete_dataset = DatasetHolder(\n",
    "            train=datasets.CityScapesForObjectDetection(root=DATA_ROOT, train=True),\n",
    "            valid=datasets.CityScapesForObjectDetection(root=DATA_ROOT, valid=True),\n",
    "            test=None\n",
    "        )\n",
    "        continuous_dataset = None\n",
    "        dataset = discrete_dataset\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported dataset: {SOURCE_DOMAIN}\")\n",
    "\n",
    "# Dataset info\n",
    "CLASSES = dataset.train.classes\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "print(f\"INFO: Number of classes - {NUM_CLASSES} {CLASSES}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check annotation keys-values\n",
    "dataset.train[999]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check data shape\n",
    "dataset.train[999][0].shape  # should be (num_channels, height, width)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize video\n",
    "visualizer.visualize_bbox_frames(dataset.train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "class DummyYOLO:\n",
    "    \"\"\"\n",
    "    Dummy YOLO model that provides helpful installation instructions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"yolo11n\"):\n",
    "        self.model_name = model_name\n",
    "        self._show_install_message()\n",
    "\n",
    "    def _show_install_message(self):\n",
    "        msg = (\n",
    "            f\"\\n{'='*70}\\n\"\n",
    "            f\"YOLO model '{self.model_name}' requires Ultralytics library.\\n\"\n",
    "            f\"{'='*70}\\n\\n\"\n",
    "            f\"To use YOLO models, install Ultralytics:\\n\"\n",
    "            f\"    pip install ultralytics\\n\\n\"\n",
    "            f\"Note: Ultralytics is licensed under AGPL-3.0.\\n\"\n",
    "            f\"By installing it, you agree to comply with AGPL-3.0 terms.\\n\"\n",
    "            f\"See: https://github.com/ultralytics/ultralytics\\n\"\n",
    "            f\"{'='*70}\\n\"\n",
    "        )\n",
    "        warnings.warn(msg, RuntimeWarning, stacklevel=2)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        raise RuntimeError(\n",
    "            f\"Cannot run YOLO model '{self.model_name}'. \"\n",
    "            f\"Install ultralytics first: pip install ultralytics\"\n",
    "        )\n",
    "\n",
    "    def predict(self, *args, **kwargs):\n",
    "        raise RuntimeError(\n",
    "            f\"Cannot run YOLO model '{self.model_name}'. \"\n",
    "            f\"Install ultralytics first: pip install ultralytics\"\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"DummyYOLO(model_name='{self.model_name}', installed=False)\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from torchvision.tv_tensors import Image, BoundingBoxFormat, BoundingBoxes\n",
    "from torchvision.transforms.v2.functional import convert_bounding_box_format\n",
    "\n",
    "from ultralytics.nn.tasks import DetectionModel\n",
    "from ultralytics.models.yolo.detect import DetectionTrainer, DetectionValidator\n",
    "\n",
    "\n",
    "\n",
    "#from ..base import BaseModel, ModelProvider, WeightsInfo\n",
    "#from ...datasets import BaseDataset, DataPreparation\n",
    "\n",
    "from ttadapters.models.base import BaseModel, ModelProvider, WeightsInfo\n",
    "from ttadapters.datasets import BaseDataset, DataPreparation\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class YOLOTrainerArguments:\n",
    "    # Basic training params\n",
    "    epochs: int = 100\n",
    "    batch: int = 16\n",
    "\n",
    "    # Optimizer params\n",
    "    optimizer: str = \"SGD\"  # SGD, Adam, AdamW, auto\n",
    "    lr0: float = 0.01  # initial learning rate\n",
    "    lrf: float = 0.01  # final learning rate (lr0 * lrf)\n",
    "    momentum: float = 0.937\n",
    "    weight_decay: float = 0.0005\n",
    "    warmup_epochs: int = 3.0\n",
    "    warmup_momentum: float = 0.8\n",
    "    warmup_bias_lr: float = 0.1\n",
    "\n",
    "    # Loss params\n",
    "    box: float = 7.5  # box loss gain\n",
    "    cls: float = 0.5  # cls loss gain\n",
    "    dfl: float = 1.5  # dfl loss gain\n",
    "\n",
    "    # Validation params\n",
    "    conf: float = 0.001  # confidence threshold\n",
    "    iou: float = 0.7  # NMS IoU threshold\n",
    "\n",
    "    # Other params\n",
    "    amp: bool = True  # automatic mixed precision\n",
    "    device: str = \"\"  # cuda device, e.g. 0 or 0,1,2,3 or cpu\n",
    "    workers: int = 0  # number of worker threads\n",
    "    project: str = \"./results\"  # project name\n",
    "    name: str = \"yolo11_training\"  # experiment name\n",
    "    exist_ok: bool = False  # overwrite existing experiment\n",
    "    seed: int = 0  # random seed\n",
    "    deterministic: bool = True  # deterministic mode\n",
    "    single_cls: bool = False  # train as single-class dataset\n",
    "    rect: bool = False  # rectangular training\n",
    "    cos_lr: bool = False  # cosine learning rate scheduler\n",
    "    close_mosaic: int = 10  # disable mosaic augmentation for final N epochs\n",
    "    resume: bool = False  # resume training\n",
    "    save: bool = True  # save checkpoints\n",
    "    save_period: int = -1  # save checkpoint every N epochs (-1 = disabled)\n",
    "    cache: bool = False  # cache images for faster training\n",
    "    val: bool = True  # validate/test during training\n",
    "    patience: int = 50  # early stopping patience (epochs without improvement)\n",
    "    plots: bool = True  # save plots during training\n",
    "\n",
    "\n",
    "class YOLOTrainer(DetectionTrainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: BaseModel,\n",
    "        classes: list[str],\n",
    "        train_dataset: DataPreparation | None = None,\n",
    "        eval_dataset: DataPreparation | None = None,\n",
    "        args: YOLOTrainerArguments | None = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.classes = classes\n",
    "        self.train_dataset = train_dataset\n",
    "        self.eval_dataset = eval_dataset\n",
    "        self.custom_args = args if args is not None else YOLOTrainerArguments()\n",
    "\n",
    "        # Convert args to YOLO cfg format\n",
    "        overrides = {k: v for k, v in vars(self.custom_args).items()}\n",
    "        overrides['model'] = model\n",
    "\n",
    "        # Initialize parent DetectionTrainer\n",
    "        super().__init__(overrides=overrides)\n",
    "\n",
    "    def get_dataset(self, dataset_path, mode=\"train\", batch_size=None):\n",
    "        if mode == 'train':\n",
    "            return self.train_dataset\n",
    "        else:\n",
    "            return self.eval_dataset\n",
    "\n",
    "    def build_dataset(self, img_path, mode=\"train\", batch=None):\n",
    "        if mode == 'train':\n",
    "            return self.train_dataset\n",
    "        else:\n",
    "            return self.eval_dataset\n",
    "\n",
    "    def get_dataloader(self, dataset_path, batch_size=16, rank=0, mode=\"train\"):\n",
    "        dataset = self.train_dataset if mode == 'train' else self.eval_dataset\n",
    "\n",
    "        return torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=(mode == 'train'),\n",
    "            collate_fn=dataset.collate_fn,\n",
    "            num_workers=self.custom_args.workers\n",
    "        )\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"Evaluate using parent's validation\"\"\"\n",
    "        metrics = self.validate()\n",
    "\n",
    "        # Convert to our format\n",
    "        results = {\n",
    "            'mAP@0.50:0.95': metrics.box.map,\n",
    "            'mAP@0.50': metrics.box.map50,\n",
    "            'mAP@0.75': metrics.box.map75,\n",
    "        }\n",
    "\n",
    "        # Add per-class mAP if available\n",
    "        if hasattr(metrics.box, 'maps'):\n",
    "            for i, class_name in enumerate(self.classes):\n",
    "                if i < len(metrics.box.maps):\n",
    "                    results[f'{class_name}_mAP@0.50:0.95'] = metrics.box.maps[i]\n",
    "\n",
    "        return results\n",
    "\n",
    "\n",
    "class YOLODataPreparation(DataPreparation, DetectionValidator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: BaseDataset,\n",
    "        dataset_key: dict = dict(bboxes=\"boxes2d\", classes=\"boxes2d_classes\", original_size=\"original_hw\"),\n",
    "        img_size: int = 640,\n",
    "        evaluation_mode: bool = False,\n",
    "        confidence_threshold: float = 0.001,\n",
    "        iou_threshold: float = 0.7,\n",
    "    ):\n",
    "        from ultralytics.data.augment import v8_transforms\n",
    "\n",
    "        self.dataset_name = dataset.dataset_name\n",
    "        self.classes = dataset.classes\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.dataset_key = dataset_key\n",
    "        self.img_size = img_size\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.evaluation_mode = evaluation_mode\n",
    "\n",
    "        # Use YOLO's pre-configured v8_transforms as augmentation\n",
    "        self.augmentation = v8_transforms(\n",
    "            dataset=dataset,\n",
    "            imgsz=img_size,\n",
    "            hyp=None,\n",
    "            stretch=False\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def transforms(self, *args, idx=None):\n",
    "        \"\"\"Apply transformations with bbox handling\"\"\"\n",
    "        image, target = args[0] if len(args) == 1 else args\n",
    "\n",
    "        bbox = target[self.dataset_key['bboxes']]\n",
    "        bbox_classes = target[self.dataset_key['classes']]\n",
    "        original_height, original_width = target[self.dataset_key['original_size']]\n",
    "\n",
    "        # Convert to numpy for YOLO transforms (YOLO uses OpenCV/numpy internally)\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.permute(1, 2, 0).numpy()  # CHW -> HWC\n",
    "\n",
    "        # Convert bbox to numpy and ensure XYXY format\n",
    "        if isinstance(bbox, BoundingBoxes):\n",
    "            if bbox.format != BoundingBoxFormat.XYXY:\n",
    "                bbox = convert_bounding_box_format(bbox, new_format=BoundingBoxFormat.XYXY)\n",
    "            bbox = bbox.data.numpy() if isinstance(bbox.data, torch.Tensor) else bbox.data\n",
    "        elif isinstance(bbox, torch.Tensor):\n",
    "            bbox = bbox.numpy()\n",
    "\n",
    "        # Convert bbox_classes to numpy\n",
    "        if isinstance(bbox_classes, torch.Tensor):\n",
    "            bbox_classes = bbox_classes.numpy()\n",
    "\n",
    "        # Apply YOLO augmentation\n",
    "        transformed = self.augmentation({\n",
    "            'img': image,\n",
    "            'bboxes': bbox,\n",
    "            'cls': bbox_classes,\n",
    "            'batch_idx': idx if idx is not None else 0\n",
    "        })\n",
    "\n",
    "        if len(args) == 1:\n",
    "            return transformed\n",
    "        else:\n",
    "            return transformed['img'], transformed\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transforms(self.dataset[idx], idx=idx)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"Use YOLO's native collate function format\"\"\"\n",
    "        images = []\n",
    "        batch_idx = []\n",
    "        cls = []\n",
    "        bboxes = []\n",
    "\n",
    "        for i, item in enumerate(batch):\n",
    "            # Convert from numpy (HWC) to torch (CHW)\n",
    "            img_tensor = torch.from_numpy(item['img']).permute(2, 0, 1)\n",
    "            images.append(img_tensor)\n",
    "\n",
    "            num_objects = len(item['bboxes'])\n",
    "            batch_idx.extend([i] * num_objects)\n",
    "            cls.extend(item['cls'].tolist())\n",
    "\n",
    "            # Convert bboxes using BoundingBoxFormat\n",
    "            boxes = item['bboxes']\n",
    "            h, w = item['img'].shape[:2]\n",
    "\n",
    "            if len(boxes) > 0:\n",
    "                # Create BoundingBoxes with XYXY format\n",
    "                boxes_tv = BoundingBoxes(\n",
    "                    torch.from_numpy(boxes),\n",
    "                    format=BoundingBoxFormat.XYXY,\n",
    "                    canvas_size=(h, w)\n",
    "                )\n",
    "\n",
    "                # Convert to CXCYWH format\n",
    "                boxes_cxcywh = convert_bounding_box_format(\n",
    "                    boxes_tv,\n",
    "                    new_format=BoundingBoxFormat.CXCYWH\n",
    "                )\n",
    "\n",
    "                # Normalize to [0, 1]\n",
    "                boxes_normalized = boxes_cxcywh.clone()\n",
    "                boxes_normalized[:, [0, 2]] /= w  # normalize cx, width\n",
    "                boxes_normalized[:, [1, 3]] /= h  # normalize cy, height\n",
    "\n",
    "                bboxes.extend(boxes_normalized.tolist())\n",
    "\n",
    "        # Stack images and normalize\n",
    "        images_tensor = torch.stack(images) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "        # Create tensors\n",
    "        if len(bboxes) > 0:\n",
    "            batch_idx_tensor = torch.tensor(batch_idx, dtype=torch.long)\n",
    "            cls_tensor = torch.tensor(cls, dtype=torch.long)\n",
    "            bboxes_tensor = torch.tensor(bboxes, dtype=torch.float32)\n",
    "        else:\n",
    "            batch_idx_tensor = torch.zeros(0, dtype=torch.long)\n",
    "            cls_tensor = torch.zeros(0, dtype=torch.long)\n",
    "            bboxes_tensor = torch.zeros((0, 4), dtype=torch.float32)\n",
    "\n",
    "        return {\n",
    "            'img': images_tensor,\n",
    "            'batch_idx': batch_idx_tensor,\n",
    "            'cls': cls_tensor,\n",
    "            'bboxes': bboxes_tensor,\n",
    "        }\n",
    "\n",
    "    def pre_process(self, batch):\n",
    "        \"\"\"Pre-process is handled by collate_fn\"\"\"\n",
    "        return batch\n",
    "\n",
    "    def post_process(self, outputs, target_sizes=None):\n",
    "        \"\"\"Use YOLO's native post-processing\"\"\"\n",
    "        from ultralytics.utils.ops import non_max_suppression\n",
    "\n",
    "        # Apply NMS\n",
    "        predictions = non_max_suppression(\n",
    "            outputs,\n",
    "            conf_thres=self.confidence_threshold,\n",
    "            iou_thres=self.iou_threshold,\n",
    "            multi_label=False,\n",
    "            max_det=300\n",
    "        )\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "class YOLO11ForObjectDetection(DetectionModel, BaseModel):\n",
    "    model_name = \"YOLO11m\"\n",
    "    model_config = \"yolo11m.yaml\"\n",
    "    model_provider = ModelProvider.Ultralytics\n",
    "    DataPreparation = YOLODataPreparation\n",
    "    Trainer = YOLOTrainer\n",
    "    TrainingArguments = YOLOTrainerArguments\n",
    "    channel = 3\n",
    "\n",
    "    class Weights:\n",
    "        COCO_OFFICIAL = WeightsInfo(\"https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt\", weight_key=\"model\")\n",
    "        SHIFT_CLEAR = WeightsInfo(\"\")\n",
    "        CITYSCAPES = WeightsInfo(\"\")\n",
    "\n",
    "    def __init__(self, dataset: BaseDataset):\n",
    "        nc = len(dataset.classes)\n",
    "        super().__init__(self.model_config, ch=self.channel, nc=nc)\n",
    "\n",
    "        self.dataset_name = dataset.dataset_name\n",
    "        self.num_classes = nc"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#TEST_MODE = False\n",
    "#MODEL_TYPE = \"yolo11\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize model\n",
    "match MODEL_TYPE:\n",
    "    case \"rcnn\":\n",
    "        model = models.FasterRCNNForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = model.load_from(**vars(model.Weights.COCO_OFFICIAL if not TEST_MODE else model.Weights.SHIFT_CLEAR_NATUREYOO if SOURCE_DOMAIN == SHIFTDataset else model.Weights.CITYSCAPES), strict=False)\n",
    "    case \"swinrcnn\":\n",
    "        model = models.SwinRCNNForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = model.load_from(**vars(model.Weights.COCO_XIAOHU2015 if not TEST_MODE else model.Weights.SHIFT_CLEAR_NATUREYOO if SOURCE_DOMAIN == SHIFTDataset else model.Weights.CITYSCAPES), strict=False)\n",
    "    case \"yolo11\":\n",
    "        model = YOLO11ForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        #model = models.YOLO11ForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = model.load_from(**vars(model.Weights.COCO_OFFICIAL if not TEST_MODE else model.Weights.SHIFT_CLEAR if SOURCE_DOMAIN == SHIFTDataset else model.Weights.CITYSCAPES), strict=False)\n",
    "    case \"rtdetr\":\n",
    "        DATA_TYPE = torch.bfloat16\n",
    "        model = models.RTDetrForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = model.load_from(**vars(model.Weights.COCO_OFFICIAL if not TEST_MODE else model.Weights.SHIFT_CLEAR if SOURCE_DOMAIN == SHIFTDataset else model.Weights.CITYSCAPES), strict=False)\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported model type: {MODEL_TYPE}\")\n",
    "\n",
    "print(\"INFO: Model state loaded -\", load_result)\n",
    "model.to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Project Setup\n",
    "PROJECT_NAME = \"tta_model_pretraining\"\n",
    "RUN_NAME = model.model_name + \"_\" + SOURCE_DOMAIN.dataset_name + (\"_test\" if TEST_MODE else \"_train\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# WandB Initialization\n",
    "import wandb\n",
    "wandb.init(project=PROJECT_NAME, name=RUN_NAME)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set Epoch Count & Learning Rate\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "evaluate_source = lambda: None\n",
    "evaluate_target = lambda: None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detectron Trainer"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define Trainer & Validator\n",
    "if not TEST_MODE and MODEL_TYPE in (\"rcnn\", \"swinrcnn\"):\n",
    "    ALL_DEVICE_BATCH = BATCH_SIZE[0]*(ADDITIONAL_GPU+1), BATCH_SIZE[1]*(ADDITIONAL_GPU+1)\n",
    "    trainer = model.Trainer(\n",
    "        model=model,\n",
    "        classes=CLASSES,\n",
    "        train_dataset=model.DataPreparation(dataset.train),\n",
    "        eval_dataset=model.DataPreparation(dataset.valid, evaluation_mode=True),\n",
    "        args=model.TrainingArguments(\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            total_steps=EPOCHS*10*len(dataset.train)//ALL_DEVICE_BATCH[0],\n",
    "            eval_period=100,\n",
    "            save_period=100,\n",
    "            train_batch_for_total=ALL_DEVICE_BATCH[0],\n",
    "            eval_batch_for_total=ALL_DEVICE_BATCH[1],\n",
    "            multiple_gpu_world_size=ADDITIONAL_GPU+1 if ADDITIONAL_GPU > 0 else ADDITIONAL_GPU,  # Set 0 to disable multi-GPU reference\n",
    "            momentum=0.9,\n",
    "            weight_decay=1e-4,\n",
    "            lr_scheduler_type=\"WarmupCosineLR\",  # WarmupMultiStepLR, WarmupStepWithFixedGammaLR\n",
    "            cosine_lr_final=LEARNING_RATE/10,\n",
    "            lr_warmup_method=\"linear\",\n",
    "            lr_warmup_iters=500,\n",
    "            use_amp=False,\n",
    "            output_dir=\"./results/\"+RUN_NAME\n",
    "        )\n",
    "    )\n",
    "\n",
    "    evaluator = model.Trainer(\n",
    "        model=model,\n",
    "        classes=CLASSES,\n",
    "        eval_dataset=model.DataPreparation(dataset.test, evaluation_mode=True),\n",
    "        args=model.TrainingArguments(\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            total_steps=1,\n",
    "            eval_batch_for_total=BATCH_SIZE[1]*(ADDITIONAL_GPU+1),\n",
    "            multiple_gpu_world_size=ADDITIONAL_GPU+1 if ADDITIONAL_GPU > 0 else ADDITIONAL_GPU,  # Set 0 to disable multi-GPU reference\n",
    "            use_amp=False,\n",
    "            output_dir=\"./results/\"+RUN_NAME\n",
    "        )\n",
    "    )\n",
    "\n",
    "    evaluate_source = trainer.test\n",
    "    evaluate_target = evaluator.test"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Ultralytics Trainer"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Transformers Trainer"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define Trainer & Validator\n",
    "if not TEST_MODE and MODEL_TYPE == \"rtdetr\":\n",
    "    trainer = model.Trainer(\n",
    "        model=model,\n",
    "        classes=CLASSES,\n",
    "        train_dataset=model.DataPreparation(dataset.train),\n",
    "        eval_dataset=model.DataPreparation(dataset.valid, evaluation_mode=True),\n",
    "        args=model.TrainingArguments(\n",
    "            backbone_learning_rate=LEARNING_RATE/10,  # Set backbone learning rate to 1/10th of the main learning rate\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            lr_scheduler_type=\"cosine\",\n",
    "            warmup_ratio=0.1,\n",
    "            weight_decay=0.1,\n",
    "            max_grad_norm=0.5,\n",
    "            num_train_epochs=EPOCHS,\n",
    "            per_device_train_batch_size=BATCH_SIZE[0],\n",
    "            per_device_eval_batch_size=BATCH_SIZE[1],\n",
    "            gradient_accumulation_steps=ACCUMULATE_STEPS,\n",
    "            eval_accumulation_steps=BATCH_SIZE[1],\n",
    "            batch_eval_metrics=True,\n",
    "            remove_unused_columns=False,\n",
    "            optim=\"adamw_torch\",\n",
    "            eval_on_start=True,\n",
    "            eval_strategy=\"steps\",\n",
    "            save_strategy=\"steps\",\n",
    "            logging_strategy=\"steps\",\n",
    "            eval_steps=100,\n",
    "            save_steps=100,\n",
    "            logging_steps=100,\n",
    "            save_total_limit=100,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"mAP@0.50:0.95\",\n",
    "            greater_is_better=True,\n",
    "            report_to=\"wandb\",\n",
    "            output_dir=\"./results/\"+RUN_NAME,\n",
    "            logging_dir=\"./logs/\"+RUN_NAME,\n",
    "            run_name=RUN_NAME,\n",
    "            bf16=True if DATA_TYPE == torch.bfloat16 else False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    evaluator = model.Trainer(\n",
    "        model=model,\n",
    "        classes=CLASSES,\n",
    "        eval_dataset=model.DataPreparation(dataset.test, evaluation_mode=True),\n",
    "        args=model.TrainingArguments(\n",
    "            per_device_eval_batch_size=BATCH_SIZE[1],\n",
    "            batch_eval_metrics=True,\n",
    "            remove_unused_columns=False,\n",
    "            bf16=True if DATA_TYPE == torch.bfloat16 else False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    evaluate_source = trainer.evaluate\n",
    "    evaluate_target = evaluator.evaluate"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Run Jobs"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Do train for source domain\n",
    "if not TEST_MODE:\n",
    "    if MODEL_TYPE in (\"rcnn\", \"swinrcnn\"):\n",
    "        trainer.resume_or_load(resume=True)\n",
    "        trainer.train()\n",
    "    elif MODEL_TYPE == \"yolo11\":\n",
    "        pass\n",
    "    elif MODEL_TYPE == \"rtdetr\":\n",
    "        try:\n",
    "            trainer.train(resume_from_checkpoint=True)\n",
    "        except (FileNotFoundError, ValueError):\n",
    "            trainer.train()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "cell_type": "code",
   "source": [
    "# Do eval for source domain\n",
    "evaluate_source()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "cell_type": "code",
   "source": [
    "# Do eval for target domain\n",
    "evaluate_target()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Model save\n",
    "if not TEST_MODE:\n",
    "    model.save_to(version=RUN_NAME)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set model eval mode\n",
    "model.eval()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Scenarios"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "|Model|Dataset|Metric|\n",
    "|---|---|---|\n",
    "|rcnn|shift|mAP@0.50:0.95|\n",
    "|swinrcnn|shift|mAP@0.50:0.95|\n",
    "|yolo11|shift|mAP@0.50:0.95|\n",
    "|rtdetr|shift|mAP@0.50:0.95|"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensure split (required due to Scenario class works with coroutines)\n",
    "_ = datasets.SHIFTContinuousSubsetForObjectDetection(root=DATA_ROOT, train=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data_preparation = model.DataPreparation(datasets.base.BaseDataset(), evaluation_mode=True)\n",
    "\n",
    "discrete_scenario = scenarios.SHIFTDiscreteScenario(\n",
    "    root=DATA_ROOT, valid=True, order=scenarios.SHIFTDiscreteScenario.WHWPAPER, transforms=data_preparation.transforms\n",
    ")\n",
    "continuous_scenario = scenarios.SHIFTContinuousScenario(\n",
    "    root=DATA_ROOT, valid=True, order=scenarios.SHIFTContinuousScenario.DEFAULT, transforms=data_preparation.transforms\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "evaluator = validator.DetectionEvaluator(model, classes=CLASSES, data_preparation=data_preparation, dtype=DATA_TYPE, device=device, no_grad=True)\n",
    "evaluator_loader_params = dict(batch_size=BATCH_SIZE[2], shuffle=False, collate_fn=data_preparation.collate_fn)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "visualizer.visualize_metrics(discrete_scenario(**evaluator_loader_params).play(evaluator, index=[\"Direct-Test\"]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "visualizer.visualize_metrics(continuous_scenario(**evaluator_loader_params).play(evaluator, index=[\"Direct-Test\"]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttadapters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
