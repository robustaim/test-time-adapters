{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training with SHIFT-Discrete Dataset (Clear-Daytime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Configs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "from os import path\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "\n",
    "from ttadapters import datasets, models\n",
    "from ttadapters.models.base import ModelProvider\n",
    "from ttadapters.utils import visualizer, validator\n",
    "from ttadapters.datasets import DatasetHolder, scenarios"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Arguments"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set Batch Size\n",
    "BATCH_SIZE = 2, 8, 1  # Local\n",
    "#BATCH_SIZE = 40, 200, 1  # A100 or H100\n",
    "ACCUMULATE_STEPS = 1\n",
    "\n",
    "# Set Data Root\n",
    "DATA_ROOT = path.join(\".\", \"data\")\n",
    "\n",
    "# Set Target Dataset\n",
    "SOURCE_DOMAIN = datasets.SHIFTDataset\n",
    "\n",
    "# Set Run Mode\n",
    "TEST_MODE = False\n",
    "\n",
    "# Set Model List\n",
    "MODEL_ZOO = [\"rcnn\", \"swinrcnn\", \"yolo11\", \"rtdetr\"]\n",
    "MODEL_TYPE = MODEL_ZOO[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create argument parser\n",
    "parser = ArgumentParser(description=\"Training script for Test-Time Adapters\")\n",
    "\n",
    "# Add model arguments\n",
    "parser.add_argument(\"--dataset\", type=str, choices=[\"shift\", \"city\"], default=\"shift\", help=\"Training dataset\")\n",
    "parser.add_argument(\"--model\", type=str, choices=MODEL_ZOO, default=MODEL_TYPE, help=\"Model architecture\")\n",
    "\n",
    "# Add training arguments\n",
    "parser.add_argument(\"--train-batch\", type=int, default=BATCH_SIZE[0], help=\"Training batch size\")\n",
    "parser.add_argument(\"--valid-batch\", type=int, default=BATCH_SIZE[1], help=\"Validation batch size\")\n",
    "parser.add_argument(\"--accum-step\", type=int, default=ACCUMULATE_STEPS, help=\"Gradient accumulation steps\")\n",
    "parser.add_argument(\"--data-root\", type=str, default=DATA_ROOT, help=\"Root directory for datasets\")\n",
    "parser.add_argument(\"--device\", type=int, default=0, help=\"CUDA device number\")\n",
    "parser.add_argument(\"--additional_gpu\", type=int, default=0, help=\"Additional CUDA device count\")\n",
    "parser.add_argument(\"--use-bf16\", action=\"store_true\", help=\"Use bfloat16 precision\")\n",
    "parser.add_argument(\"--test-only\", action=\"store_true\", help=\"Run in test-only mode\")\n",
    "\n",
    "# Parsing arguments\n",
    "if \"ipykernel\" in sys.modules:\n",
    "    args = parser.parse_args([])\n",
    "    print(\"INFO: Running in notebook mode with default arguments\")\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# Update global variables based on parsed arguments\n",
    "BATCH_SIZE = args.train_batch, args.valid_batch, BATCH_SIZE[2]\n",
    "ACCUMULATE_STEPS = args.accum_step\n",
    "DATA_ROOT = args.data_root\n",
    "TEST_MODE = args.test_only\n",
    "MODEL_TYPE = args.model\n",
    "match args.dataset:\n",
    "    case \"shift\":\n",
    "        SOURCE_DOMAIN = datasets.SHIFTDataset\n",
    "    case \"city\":\n",
    "        SOURCE_DOMAIN = datasets.CityscapesDataset\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported dataset: {args.dataset}\")\n",
    "print(f\"INFO: Set batch size - Train: {BATCH_SIZE[0]}, Valid: {BATCH_SIZE[1]}, Test: {BATCH_SIZE[2]}\")\n",
    "print(f\"INFO: Set test mode - {TEST_MODE} for {SOURCE_DOMAIN.dataset_name} dataset\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!nvidia-smi"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set CUDA Device Number\n",
    "DEVICE_NUM = 0 if not args.device else args.device\n",
    "ADDITIONAL_GPU = 0 if not args.additional_gpu else args.additional_gpu\n",
    "DATA_TYPE = torch.float32 if not args.use_bf16 else torch.bfloat16\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if ADDITIONAL_GPU:\n",
    "        torch.cuda.set_device(DEVICE_NUM)\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{DEVICE_NUM}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DEVICE_NUM = -1\n",
    "\n",
    "print(f\"INFO: Using device - {device}\" + (f\":{DEVICE_NUM}\" if ADDITIONAL_GPU else \"\"))\n",
    "print(f\"INFO: Using data precision - {DATA_TYPE}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Fast download patch\n",
    "datasets.patch_fast_download_for_object_detection()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Basic pre-training dataset\n",
    "match SOURCE_DOMAIN:\n",
    "    case datasets.SHIFTDataset:\n",
    "        dataset = DatasetHolder(\n",
    "            train=datasets.SHIFTClearDatasetForObjectDetection(root=DATA_ROOT, train=True),\n",
    "            valid=datasets.SHIFTClearDatasetForObjectDetection(root=DATA_ROOT, valid=True),\n",
    "            test=datasets.SHIFTCorruptedDatasetForObjectDetection(root=DATA_ROOT, valid=True)\n",
    "        )\n",
    "    case datasets.CityscapesDataset:\n",
    "        pass\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported dataset: {SOURCE_DOMAIN}\")\n",
    "\n",
    "# Dataset info\n",
    "CLASSES = dataset.train.classes\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "print(f\"INFO: Number of classes - {NUM_CLASSES} {CLASSES}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check annotation keys-values\n",
    "dataset.train[999]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Check data shape\n",
    "dataset.train[999][0].shape  # should be (num_channels, height, width)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize video\n",
    "visualizer.visualize_bbox_frames(dataset.train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "\n",
    "class DummyYOLO:\n",
    "    \"\"\"\n",
    "    Dummy YOLO model that provides helpful installation instructions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"yolo11n\"):\n",
    "        self.model_name = model_name\n",
    "        self._show_install_message()\n",
    "\n",
    "    def _show_install_message(self):\n",
    "        msg = (\n",
    "            f\"\\n{'='*70}\\n\"\n",
    "            f\"YOLO model '{self.model_name}' requires Ultralytics library.\\n\"\n",
    "            f\"{'='*70}\\n\\n\"\n",
    "            f\"To use YOLO models, install Ultralytics:\\n\"\n",
    "            f\"    pip install ultralytics\\n\\n\"\n",
    "            f\"Note: Ultralytics is licensed under AGPL-3.0.\\n\"\n",
    "            f\"By installing it, you agree to comply with AGPL-3.0 terms.\\n\"\n",
    "            f\"See: https://github.com/ultralytics/ultralytics\\n\"\n",
    "            f\"{'='*70}\\n\"\n",
    "        )\n",
    "        warnings.warn(msg, RuntimeWarning, stacklevel=2)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        raise RuntimeError(\n",
    "            f\"Cannot run YOLO model '{self.model_name}'. \"\n",
    "            f\"Install ultralytics first: pip install ultralytics\"\n",
    "        )\n",
    "\n",
    "    def predict(self, *args, **kwargs):\n",
    "        raise RuntimeError(\n",
    "            f\"Cannot run YOLO model '{self.model_name}'. \"\n",
    "            f\"Install ultralytics first: pip install ultralytics\"\n",
    "        )\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"DummyYOLO(model_name='{self.model_name}', installed=False)\"\n",
    "\n",
    "\n",
    "def load_yolo_model(model_name: str = \"yolo11n\", **kwargs):\n",
    "    \"\"\"\n",
    "    Load YOLO model if Ultralytics is installed, otherwise return DummyYOLO.\n",
    "\n",
    "    Args:\n",
    "        model_name: YOLO model variant (e.g., 'yolo11n', 'yolo11s', 'yolo11m')\n",
    "        **kwargs: Additional arguments passed to YOLO constructor\n",
    "\n",
    "    Returns:\n",
    "        YOLO model instance or DummyYOLO with installation instructions\n",
    "\n",
    "    Examples:\n",
    "        >>> model = load_yolo_model('yolo11n')\n",
    "        >>> # If ultralytics installed: returns real YOLO\n",
    "        >>> # If not installed: returns DummyYOLO with helpful message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from ultralytics import YOLO\n",
    "        print(f\"✓ Loaded YOLO model: {model_name}\")\n",
    "        return YOLO(model_name, **kwargs)\n",
    "\n",
    "    except ImportError:\n",
    "        print(f\"✗ Ultralytics not installed. Returning DummyYOLO for '{model_name}'\")\n",
    "        return DummyYOLO(model_name=model_name)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from ultralytics.nn.tasks import DetectionModel\n",
    "from ttadapters.models.base import BaseModel, WeightsInfo\n",
    "from ttadapters.datasets import BaseDataset\n",
    "\n",
    "from ultralytics.models.yolo.detect import DetectionTrainer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torchvision.tv_tensors import BoundingBoxFormat\n",
    "from torchvision.transforms.v2.functional import convert_bounding_box_format\n",
    "import torch\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    batch_idx = []\n",
    "    cls = []\n",
    "    bboxes = []\n",
    "    ori_shapes = []\n",
    "    ratio_pads = []\n",
    "\n",
    "    for idx, (image, metadata) in enumerate(batch):\n",
    "        resized_height, resized_width = image.shape[-2:]\n",
    "        original_height, original_width = metadata['original_hw']\n",
    "        ori_shapes.append([original_height, original_width])\n",
    "\n",
    "        boxes = metadata[\"boxes2d\"]  # xyxy\n",
    "        classes = metadata[\"boxes2d_classes\"]\n",
    "        boxes_cxcywh = convert_bounding_box_format(boxes, new_format=BoundingBoxFormat.CXCYWH)\n",
    "\n",
    "        images.append(image)\n",
    "        batch_idx_list.extend([idx] * len(boxes))\n",
    "        cls_list.extend(classes.tolist())\n",
    "        bboxes_list.extend(boxes_normalized.tolist())\n",
    "\n",
    "    images_list = MaskedImageList.from_tensors(images)\n",
    "    if len(bboxes_list) > 0:\n",
    "        batch_idx_tensor = torch.tensor(batch_idx_list, dtype=torch.long)\n",
    "        cls_tensor = torch.tensor(cls_list, dtype=torch.long)\n",
    "        bboxes_tensor = torch.tensor(bboxes_list, dtype=torch.float32)\n",
    "    else:  # no objects in the batch\n",
    "        batch_idx_tensor = torch.zeros(0, dtype=torch.long)\n",
    "        cls_tensor = torch.zeros(0, dtype=torch.long)\n",
    "        bboxes_tensor = torch.zeros((0, 4), dtype=torch.float32)\n",
    "\n",
    "    return {\n",
    "        'img': images_list.tensor,              # Shape: [batch_size, 3, height, width]\n",
    "        'batch_idx': batch_idx_tensor,          # Shape: [num_objects] - batch indices\n",
    "        'cls': cls_tensor,                      # Shape: [num_objects] - class indices\n",
    "        'bboxes': bboxes_tensor,                # Shape: [num_objects, 4] - normalized cxcywh (0~1)\n",
    "        'ori_shapes': torch.tensor(ori_shapes), # Shape: [batch_size, 2] - original (height, width)\n",
    "        'ratio_pads': torch.tensor(ratio_pads)  # Shape: [batch_size, 2, 2] - [[ratio, ratio], [pad_w, pad_h]]\n",
    "    }\n",
    "\n",
    "\n",
    "class YOLOTrainer():\n",
    "    pass\n",
    "\n",
    "\n",
    "class YOLODataPreparation():\n",
    "    pass\n",
    "\n",
    "\n",
    "class YOLO11ForObjectDetection(DetectionModel, BaseModel):\n",
    "    model_name = \"YOLO11\"\n",
    "    model_config = \"yolo11m.yaml\"\n",
    "    model_provider = ModelProvider.Ultralytics\n",
    "    channel = 3\n",
    "\n",
    "    class Weights:\n",
    "        COCO = WeightsInfo(\"https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt\", weight_key=\"model\")\n",
    "        SHIFT_CLEAR = WeightsInfo(\"\")\n",
    "\n",
    "    def __init__(self, dataset: BaseDataset):\n",
    "        nc = len(dataset.classes)\n",
    "        super().__init__(self.model_config, ch=self.channel, nc=nc)\n",
    "\n",
    "        self.dataset_name = dataset.dataset_name\n",
    "        self.num_classes = nc"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TEST_MODE = False\n",
    "MODEL_TYPE = \"yolo11\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize model\n",
    "match MODEL_TYPE:\n",
    "    case \"rcnn\":\n",
    "        model = models.FasterRCNNForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = model.load_from(**vars(model.Weights.SHIFT_CLEAR_NATUREYOO if TEST_MODE else model.Weights.IMAGENET_OFFICIAL), strict=False)\n",
    "    case \"swinrcnn\":\n",
    "        model = models.SwinRCNNForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = model.load_from(**vars(model.Weights.SHIFT_CLEAR_NATUREYOO if TEST_MODE else model.Weights.IMAGENET_XIAOHU2015), strict=False)\n",
    "    case \"yolo11\":\n",
    "        model = YOLO11ForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        #model = models.YOLO11ForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = model.load_from(**vars(model.Weights.SHIFT_CLEAR if TEST_MODE else model.Weights.COCO_OFFICIAL), strict=False)\n",
    "    case \"rtdetr\":\n",
    "        model = models.RTDetrForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = model.load_from(**vars(model.Weights.SHIFT_CLEAR if TEST_MODE else model.Weights.COCO_OFFICIAL), strict=False)\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported model type: {MODEL_TYPE}\")\n",
    "\n",
    "print(\"INFO: Model state loaded -\", load_result)\n",
    "model.to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compile model\n",
    "model = torch.compile(model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "PROJECT_NAME = \"tta_model_pretraining\"\n",
    "RUN_NAME = model.model_name + \"_\" + SOURCE_DOMAIN.dataset_name + (\"_test\" if TEST_MODE else \"_train\")\n",
    "\n",
    "# WandB Initialization\n",
    "import wandb\n",
    "wandb.init(project=PROJECT_NAME, name=RUN_NAME)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set Epoch Count & Learning Rate\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detectron Trainer"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define Trainer & Validator\n",
    "if not TEST_MODE and MODEL_TYPE in (\"rcnn\", \"swinrcnn\"):\n",
    "    ALL_DEVICE_BATCH = BATCH_SIZE[0]*(ADDITIONAL_GPU+1), BATCH_SIZE[1]*(ADDITIONAL_GPU+1)\n",
    "    trainer = model.Trainer(\n",
    "        model=model,\n",
    "        classes=CLASSES,\n",
    "        train_dataset=model.DataPreparation(dataset.train),\n",
    "        eval_dataset=model.DataPreparation(dataset.valid, evaluation_mode=True),\n",
    "        args=model.TrainingArguments(\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            total_steps=EPOCHS*len(dataset.train)//ALL_DEVICE_BATCH[0],\n",
    "            eval_period=100,\n",
    "            save_period=100,\n",
    "            train_batch_for_total=ALL_DEVICE_BATCH[0],\n",
    "            eval_batch_for_total=ALL_DEVICE_BATCH[1],\n",
    "            multiple_gpu_world_size=ADDITIONAL_GPU+1 if ADDITIONAL_GPU > 0 else ADDITIONAL_GPU,  # Set 0 to disable multi-GPU reference\n",
    "            momentum=0.9,\n",
    "            weight_decay=1e-4,\n",
    "            lr_scheduler_type=\"WarmupCosineLR\",  # WarmupMultiStepLR, WarmupStepWithFixedGammaLR\n",
    "            cosine_lr_final=LEARNING_RATE/10,\n",
    "            lr_warmup_method=\"linear\",\n",
    "            lr_warmup_iters=500,\n",
    "            use_amp=False,\n",
    "            output_dir=\"./results/\"+RUN_NAME\n",
    "        )\n",
    "    )\n",
    "\n",
    "    evaluator = model.Trainer(\n",
    "        model=model,\n",
    "        classes=CLASSES,\n",
    "        eval_dataset=model.DataPreparation(dataset.valid, evaluation_mode=True),\n",
    "        args=model.TrainingArguments(\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            total_steps=1,\n",
    "            eval_batch_for_total=BATCH_SIZE[1]*(ADDITIONAL_GPU+1),\n",
    "            multiple_gpu_world_size=ADDITIONAL_GPU+1 if ADDITIONAL_GPU > 0 else ADDITIONAL_GPU,  # Set 0 to disable multi-GPU reference\n",
    "            use_amp=False,\n",
    "            output_dir=\"./results/\"+RUN_NAME\n",
    "        )\n",
    "    )\n",
    "\n",
    "    evaluate_source = trainer.test\n",
    "    evaluate_target = evaluator.test"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Ultralytics Trainer"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Transformers Trainer"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define Trainer & Validator\n",
    "if not TEST_MODE and MODEL_TYPE == \"rtdetr\":\n",
    "    trainer = model.Trainer(\n",
    "        model=model,\n",
    "        classes=CLASSES,\n",
    "        train_dataset=model.DataPreparation(dataset.train),\n",
    "        eval_dataset=model.DataPreparation(dataset.valid, evaluation_mode=True),\n",
    "        args=model.TrainingArguments(\n",
    "            backbone_learning_rate=LEARNING_RATE/10,  # Set backbone learning rate to 1/10th of the main learning rate\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            lr_scheduler_type=\"cosine\",\n",
    "            warmup_ratio=0.1,\n",
    "            weight_decay=0.1,\n",
    "            max_grad_norm=0.5,\n",
    "            num_train_epochs=EPOCHS,\n",
    "            per_device_train_batch_size=BATCH_SIZE[0],\n",
    "            per_device_eval_batch_size=BATCH_SIZE[1],\n",
    "            gradient_accumulation_steps=ACCUMULATE_STEPS,\n",
    "            eval_accumulation_steps=BATCH_SIZE[1],\n",
    "            batch_eval_metrics=True,\n",
    "            remove_unused_columns=False,\n",
    "            optim=\"adamw_torch\",\n",
    "            eval_on_start=True,\n",
    "            eval_strategy=\"epoch\",  #\"steps\",\n",
    "            save_strategy=\"epoch\",  #\"steps\",\n",
    "            logging_strategy=\"epoch\",  #\"steps\",\n",
    "            #eval_steps=100,\n",
    "            #save_steps=100,\n",
    "            #logging_steps=100,\n",
    "            save_total_limit=100,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"mAP@0.50:0.95\",\n",
    "            greater_is_better=True,\n",
    "            report_to=\"wandb\",\n",
    "            output_dir=\"./results/\"+RUN_NAME,\n",
    "            logging_dir=\"./logs/\"+RUN_NAME,\n",
    "            run_name=RUN_NAME,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    evaluator = model.Trainer(\n",
    "        model=model,\n",
    "        classes=CLASSES,\n",
    "        eval_dataset=model.DataPreparation(dataset.test, evaluation_mode=True),\n",
    "        args=model.TrainingArguments(\n",
    "            per_device_eval_batch_size=BATCH_SIZE[1],\n",
    "            batch_eval_metrics=True,\n",
    "            remove_unused_columns=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    evaluate_source = trainer.evaluate\n",
    "    evaluate_target = evaluator.evaluate"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Run Jobs"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Do train for source domain\n",
    "if not TEST_MODE:\n",
    "    if MODEL_TYPE in (\"rcnn\", \"swinrcnn\"):\n",
    "        trainer.resume_or_load(resume=True)\n",
    "        trainer.train()\n",
    "    elif MODEL_TYPE == \"yolo11\":\n",
    "        pass\n",
    "    elif MODEL_TYPE == \"rtdetr\":\n",
    "        try:\n",
    "            trainer.train(resume_from_checkpoint=True)\n",
    "        except (FileNotFoundError, ValueError):\n",
    "            trainer.train()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "cell_type": "code",
   "source": [
    "# Do eval for source domain\n",
    "if not TEST_MODE: evaluate_source()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "cell_type": "code",
   "source": [
    "# Do eval for target domain\n",
    "if not TEST_MODE: evaluate_target()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Model save\n",
    "if not TEST_MODE: model.save_to(version=RUN_NAME)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Scenarios"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensure split (required due to Scenario class works with coroutines)\n",
    "_ = datasets.SHIFTContinuousSubsetForObjectDetection(root=DATA_ROOT, train=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data_preparation = model.DataPreparation(datasets.base.BaseDataset(), evaluation_mode=True)\n",
    "\n",
    "discrete_scenario = scenarios.SHIFTDiscreteScenario(\n",
    "    root=DATA_ROOT, valid=True, order=scenarios.SHIFTDiscreteScenario.WHWPAPER, transforms=data_preparation.transforms\n",
    ")\n",
    "continuous_scenario = scenarios.SHIFTContinuousScenario(\n",
    "    root=DATA_ROOT, valid=True, order=scenarios.SHIFTContinuousScenario.DEFAULT, transforms=data_preparation.transforms\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "evaluator = validator.DetectionEvaluator(model, classes=CLASSES, data_preparation=data_preparation, dtype=DATA_TYPE, device=device)\n",
    "evaluator_loader_params = dict(batch_size=BATCH_SIZE[2], shuffle=False, collate_fn=data_preparation.collate_fn)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "visualizer.visualize_metrics(discrete_scenario(**evaluator_loader_params).play(evaluator, index=[\"Direct-Test\"]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "visualizer.visualize_metrics(continuous_scenario(**evaluator_loader_params).play(evaluator, index=[\"Direct-Test\"]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttadapters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
