{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RT-DETR Pretraining with SHIFT-Discrete Dataset"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from os import path\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from ttadapters.models import RTDetr50ForObjectDetection\n",
    "from ttadapters.datasets import DatasetHolder, DataLoaderHolder\n",
    "from ttadapters.datasets import SHIFTDiscreteDatasetForObjectDetection\n",
    "from transformers import Trainer, TrainingArguments, DefaultDataCollator, EarlyStoppingCallback\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check GPU Availability"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!nvidia-smi",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set CUDA Device Number 0~7\n",
    "DEVICE_NUM = 0\n",
    "ADDITIONAL_GPU = 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if ADDITIONAL_GPU:\n",
    "        torch.cuda.set_device(DEVICE_NUM)\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{DEVICE_NUM}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DEVICE_NUM = -1\n",
    "\n",
    "print(f\"INFO: Using device - {device}\" + (f\":{DEVICE_NUM}\" if ADDITIONAL_GPU else \"\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Dataset"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATA_ROOT = path.join(\".\", \"data\")\n",
    "\n",
    "dataset = DatasetHolder(\n",
    "    train=SHIFTDiscreteDatasetForObjectDetection(root=DATA_ROOT, train=True),\n",
    "    valid=SHIFTDiscreteDatasetForObjectDetection(root=DATA_ROOT, valid=True)\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset.train[1]['front'].keys()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataset.train[1000]",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for _ in range(2):\n",
    "#     selected_idx = train_dataset.output_sampling(img_norm=IMG_NORM, imgsize=(IMG_SIZE, IMG_SIZE))\n",
    "#     print(f\"Visualized pair index: {selected_idx}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DataLoader"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class DatasetAdapter(Dataset):\n",
    "    preprocessor = RTDetr50ForObjectDetection.image_processor\n",
    "\n",
    "    def __init__(self, shift_dataset, camera='front'):\n",
    "        self.dataset = shift_dataset\n",
    "        self.camera = camera\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx][self.camera]\n",
    "        orig_h, orig_w = item[\"images\"].shape[:2]\n",
    "\n",
    "        processed_image = self.preprocessor(\n",
    "            item[\"images\"],\n",
    "            do_resize=True,\n",
    "            size={\"height\": 640, \"width\": 640},\n",
    "            return_tensors=\"pt\"\n",
    "        ).pixel_values.squeeze(0)\n",
    "\n",
    "        boxes = item[\"boxes2d\"].clone()\n",
    "\n",
    "        boxes[:, 0] = boxes[:, 0] * (640 / orig_w)  # x_min\n",
    "        boxes[:, 1] = boxes[:, 1] * (640 / orig_h)  # y_min\n",
    "        boxes[:, 2] = boxes[:, 2] * (640 / orig_w)  # x_max\n",
    "        boxes[:, 3] = boxes[:, 3] * (640 / orig_h)  # y_max\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": processed_image,\n",
    "            \"labels\": item['boxes2d_classes'],\n",
    "            \"boxes\": boxes\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ObjectDetectionDataCollator:\n",
    "    def __call__(self, batch):\n",
    "        pixel_values = torch.stack([item[\"pixel_values\"] for item in batch])\n",
    "        targets = []\n",
    "        for item in batch:\n",
    "            target = {\n",
    "                \"class_labels\": item[\"labels\"],\n",
    "                \"boxes\": item[\"boxes\"]\n",
    "            }\n",
    "            targets.append(target)\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": pixel_values,\n",
    "            \"labels\": targets\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set Batch Size\n",
    "BATCH_SIZE = 8, 4, 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set Epoch Count & Learning Rate\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 1e-4, 1e-6  # Initial LR, minimum LR\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE[0],\n",
    "    per_device_eval_batch_size=BATCH_SIZE[1],\n",
    "    learning_rate=LEARNING_RATE[0],\n",
    "    remove_unused_columns=False,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = RTDetr50ForObjectDetection.from_pretrained(num_labels=len(dataset.train.categories))\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=DatasetAdapter(dataset.train),\n",
    "    eval_dataset=DatasetAdapter(dataset.valid),\n",
    "    data_collator=ObjectDetectionDataCollator,\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")\n",
    "\n",
    "if ADDITIONAL_GPU:\n",
    "    model = nn.DataParallel(model, device_ids=list(range(DEVICE_NUM, DEVICE_NUM+ADDITIONAL_GPU+1)))\n",
    "model.to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.train()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
