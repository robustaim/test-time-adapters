{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced APT Example with Ideas A, B, C, D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements Overview\n",
    "\n",
    "**Idea A: Loss-based Adaptation Control**\n",
    "- Loss spike detection for domain change → optimizer reset\n",
    "- Loss threshold for skipping bad updates\n",
    "- Loss history tracking for statistical analysis\n",
    "\n",
    "**Idea B: Extended Adaptation Scope**\n",
    "- Conv layers before BatchNorm\n",
    "- MLP layers after LayerNorm/BatchNorm\n",
    "- Better feature adaptation capability\n",
    "\n",
    "**Idea C: Gradient Scaling**\n",
    "- Inverse relationship with loss magnitude\n",
    "- Small losses → larger gradients (fine-tuning)\n",
    "- Large losses → smaller gradients (stability)\n",
    "\n",
    "**Idea D: BN Statistics Update**\n",
    "- Running mean/var updated via backprop\n",
    "- Better adaptation to distribution shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import path, environ\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "from ttadapters import datasets, models, methods\n",
    "from ttadapters.utils import visualizer, validator\n",
    "from ttadapters.datasets import DatasetHolder, scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environ[\"TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS\"] = \"1\"\n",
    "environ[\"TORCHDYNAMO_CAPTURE_DYNAMIC_OUTPUT_SHAPE_OPS\"] = \"1\"\n",
    "\n",
    "torch._dynamo.config.capture_scalar_outputs = True\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Batch Size\n",
    "BATCH_SIZE = 2, 8, 1  # Local\n",
    "#BATCH_SIZE = 40, 200, 1  # A100 or H100\n",
    "ACCUMULATE_STEPS = 1\n",
    "\n",
    "# Set Data Root\n",
    "DATA_ROOT = path.join(\".\", \"data\")\n",
    "\n",
    "# Set Target Dataset\n",
    "SOURCE_DOMAIN = datasets.SHIFTDataset\n",
    "\n",
    "# Set Model List\n",
    "MODEL_ZOO = [\"rcnn\", \"swinrcnn\", \"yolo11\", \"rtdetr\"]\n",
    "MODEL_TYPE = MODEL_ZOO[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create argument parser\n",
    "parser = ArgumentParser(description=\"Enhanced APT experiment script\")\n",
    "\n",
    "parser.add_argument(\"--dataset\", type=str, choices=[\"shift\", \"city\"], default=\"shift\")\n",
    "parser.add_argument(\"--model\", type=str, choices=MODEL_ZOO, default=MODEL_TYPE)\n",
    "parser.add_argument(\"--train-batch\", type=int, default=BATCH_SIZE[0])\n",
    "parser.add_argument(\"--valid-batch\", type=int, default=BATCH_SIZE[1])\n",
    "parser.add_argument(\"--accum-step\", type=int, default=ACCUMULATE_STEPS)\n",
    "parser.add_argument(\"--data-root\", type=str, default=DATA_ROOT)\n",
    "parser.add_argument(\"--device\", type=int, default=0)\n",
    "parser.add_argument(\"--additional_gpu\", type=int, default=0)\n",
    "parser.add_argument(\"--use-bf16\", action=\"store_true\")\n",
    "\n",
    "if \"ipykernel\" in sys.modules:\n",
    "    args = parser.parse_args([])\n",
    "    print(\"INFO: Running in notebook mode with default arguments\")\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "BATCH_SIZE = args.train_batch, args.valid_batch, BATCH_SIZE[2]\n",
    "ACCUMULATE_STEPS = args.accum_step\n",
    "DATA_ROOT = args.data_root\n",
    "MODEL_TYPE = args.model\n",
    "match args.dataset:\n",
    "    case \"shift\":\n",
    "        SOURCE_DOMAIN = datasets.SHIFTDataset\n",
    "    case \"city\":\n",
    "        SOURCE_DOMAIN = datasets.CityScapesDataset\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported dataset: {args.dataset}\")\n",
    "print(f\"INFO: Batch size - Train: {BATCH_SIZE[0]}, Valid: {BATCH_SIZE[1]}, Test: {BATCH_SIZE[2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_NUM = 0 if not args.device else args.device\n",
    "ADDITIONAL_GPU = 0 if not args.additional_gpu else args.additional_gpu\n",
    "DATA_TYPE = torch.float32 if not args.use_bf16 else torch.bfloat16\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if ADDITIONAL_GPU:\n",
    "        torch.cuda.set_device(DEVICE_NUM)\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{DEVICE_NUM}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DEVICE_NUM = -1\n",
    "\n",
    "print(f\"INFO: Using device - {device}\" + (f\":{DEVICE_NUM}\" if ADDITIONAL_GPU else \"\"))\n",
    "print(f\"INFO: Using data precision - {DATA_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.patch_fast_download_for_object_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = datasets.SHIFTClearDatasetForObjectDetection.classes\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "print(f\"INFO: Number of classes - {NUM_CLASSES} {CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match MODEL_TYPE:\n",
    "    case \"rcnn\":\n",
    "        base_model = models.FasterRCNNForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = base_model.load_from(**vars(base_model.Weights.SHIFT_CLEAR_NATUREYOO if SOURCE_DOMAIN == datasets.SHIFTDataset else base_model.Weights.CITYSCAPES), strict=False)\n",
    "    case \"swinrcnn\":\n",
    "        base_model = models.SwinRCNNForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = base_model.load_from(**vars(base_model.Weights.SHIFT_CLEAR_NATUREYOO if SOURCE_DOMAIN == datasets.SHIFTDataset else base_model.Weights.CITYSCAPES), strict=False)\n",
    "    case \"yolo11\":\n",
    "        DATA_TYPE = torch.bfloat16\n",
    "        base_model = models.YOLO11ForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = base_model.load_from(**vars(base_model.Weights.SHIFT_CLEAR if SOURCE_DOMAIN == datasets.SHIFTDataset else base_model.Weights.CITYSCAPES), strict=False)\n",
    "    case \"rtdetr\":\n",
    "        DATA_TYPE = torch.bfloat16\n",
    "        base_model = models.RTDetrForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = base_model.load_from(**vars(base_model.Weights.SHIFT_CLEAR if SOURCE_DOMAIN == datasets.SHIFTDataset else base_model.Weights.CITYSCAPES), strict=False)\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported model type: {MODEL_TYPE}\")\n",
    "\n",
    "print(\"INFO: Model state loaded -\", load_result)\n",
    "base_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Enhanced APT Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_config = methods.APTConfig.with_idea_B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_config.adaptation_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize enhanced APT engine\n",
    "adaptive_model = methods.APTEngine(base_model, adaptive_config)\n",
    "adaptive_model.to(device)\n",
    "print(f\"\\nModel: {adaptive_model.model_name}\")\n",
    "print(f\"Number of adaptable parameters: {sum(p.numel() for p in adaptive_model.online_parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.eval()\n",
    "adaptive_model.online()\n",
    "summary(adaptive_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = datasets.SHIFTContinuousSubsetForObjectDetection(root=DATA_ROOT, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preparation = base_model.DataPreparation(datasets.base.BaseDataset(), evaluation_mode=True)\n",
    "\n",
    "match SOURCE_DOMAIN:\n",
    "    case datasets.SHIFTDataset:\n",
    "        discrete_scenario = scenarios.SHIFTDiscreteScenario(\n",
    "            root=DATA_ROOT, valid=True, order=scenarios.SHIFTDiscreteScenario.WHWPAPER, transforms=data_preparation.transforms\n",
    "        )\n",
    "    case datasets.CityScapesDataset:\n",
    "        discrete_scenario = None\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported dataset: {SOURCE_DOMAIN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_dict = {\n",
    "    #'Direct-Test': base_model,\n",
    "    adaptive_model.model_name: adaptive_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = validator.DetectionEvaluator(\n",
    "    list(methods_dict.values()), \n",
    "    classes=CLASSES, \n",
    "    data_preparation=data_preparation, \n",
    "    dtype=DATA_TYPE, \n",
    "    device=device, \n",
    "    no_grad=False\n",
    ")\n",
    "evaluator_loader_params = dict(\n",
    "    batch_size=BATCH_SIZE[2], \n",
    "    shuffle=False, \n",
    "    collate_fn=data_preparation.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting evaluation with enhanced APT...\")\n",
    "print(\"Monitoring: domain changes, skipped updates, loss statistics\\n\")\n",
    "\n",
    "results = visualizer.visualize_metrics(\n",
    "    discrete_scenario(**evaluator_loader_params).play(evaluator, index=methods_dict.keys())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting evaluation with enhanced APT...\")\n",
    "print(\"Monitoring: domain changes, skipped updates, loss statistics\\n\")\n",
    "\n",
    "results = visualizer.visualize_metrics(\n",
    "    discrete_scenario(**evaluator_loader_params).play(evaluator, index=methods_dict.keys())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting evaluation with enhanced APT...\")\n",
    "print(\"Monitoring: domain changes, skipped updates, loss statistics\\n\")\n",
    "\n",
    "results = visualizer.visualize_metrics(\n",
    "    discrete_scenario(**evaluator_loader_params).play(evaluator, index=methods_dict.keys())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Adaptation Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = adaptive_model.get_adaptation_stats()\n",
    "print(\"\\nAdaptation Statistics:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key:30s}: {value:10.4f}\")\n",
    "    else:\n",
    "        print(f\"{key:30s}: {value:10d}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis and Comparison\n",
    "\n",
    "Key metrics to observe:\n",
    "1. **Domain changes detected**: Should increase when conditions shift dramatically\n",
    "2. **Skipped updates**: Shows robustness against bad gradients\n",
    "3. **Loss statistics**: Mean/std/min/max show adaptation behavior\n",
    "4. **mAP improvements**: Overall performance gain from adaptation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttadapters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
