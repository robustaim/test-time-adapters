{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf7134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_on_dataset_online_adaptation(cfg, model, data_loader, optimizer, evaluator, d_idx, wandb, teacher_model=None, val_data_loader=None, val_evaluator=None, loss_ema99=0, loss_ema95=0, loss_ema90=0, is_used=0, domain_name=None):\n",
    "    \"\"\"\n",
    "    Run model on the data_loader and evaluate the metrics with evaluator.\n",
    "    Also benchmark the inference speed of `model.forward` accurately.\n",
    "    The model will be used in eval mode.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): a module which accepts an object from\n",
    "            `data_loader` and returns some outputs. It will be temporarily set to `eval` mode.\n",
    "\n",
    "            If you wish to evaluate a model in `training` mode instead, you can\n",
    "            wrap the given model and override its behavior of `.eval()` and `.train()`.\n",
    "        data_loader: an iterable object with a length.\n",
    "            The elements it generates will be the inputs to the model.\n",
    "        evaluator (DatasetEvaluator): the evaluator to run. Use `None` if you only want\n",
    "            to benchmark, but don't want to do any evaluation.\n",
    "\n",
    "    Returns:\n",
    "        The return value of `evaluator.evaluate()`\n",
    "    \"\"\"\n",
    "    num_devices = get_world_size()\n",
    "    logger = logging.getLogger(__name__)\n",
    "    # logger.info(\"Start inference on {} images\".format(len(data_loader)))\n",
    "\n",
    "    total = len(data_loader)  # inference data loader must have a fixed length\n",
    "    if evaluator is None:\n",
    "        # create a no-op evaluator\n",
    "        evaluator = DatasetEvaluators([])\n",
    "    evaluator.reset()\n",
    "    if val_evaluator is not None:\n",
    "        val_evaluator.reset()\n",
    "\n",
    "    num_warmup = min(5, total - 1)\n",
    "    start_time = time.perf_counter()\n",
    "    total_compute_time = 0\n",
    "    batch_size = cfg.SOLVER.IMS_PER_BATCH_TEST\n",
    "    cur_used = True\n",
    "    prev_used = is_used\n",
    "    f_sim = {}\n",
    "    div_thr = 2* sum(model.s_div.values()) * cfg.TEST.ADAPTATION.SKIP_TAU if cfg.TEST.ADAPTATION.SKIP_REDUNDANT is not None else 2* sum(model.s_div.values())\n",
    "    # for weight regularization\n",
    "    init_weights = []\n",
    "    for p_idx, _p in enumerate(optimizer.param_groups):\n",
    "        p = _p['params'][0]\n",
    "        init_weights.append(p.clone().detach())\n",
    "\n",
    "    with EventStorage() as storage:\n",
    "        for idx, inputs in enumerate(data_loader):\n",
    "            if idx == num_warmup:\n",
    "                start_time = time.perf_counter()\n",
    "                total_compute_time = 0\n",
    "            if idx == total:\n",
    "                break\n",
    "\n",
    "            start_compute_time = time.perf_counter()\n",
    "\n",
    "            cur_step = (d_idx * len(data_loader) + idx) * batch_size\n",
    "            #if idx / len(data_loader) < cfg.TEST.ADAPTATION.STOP:\\\n",
    "            if cur_used or (not cur_used and pause_iter % cfg.TEST.ADAPTATION.SKIP_PERIOD == 0) or ('period' in cfg.TEST.ADAPTATION.SKIP_REDUNDANT and idx % cfg.TEST.ADAPTATION.SKIP_PERIOD == 0):\n",
    "                \n",
    "                outputs, losses, feature_sim = model(inputs)\n",
    "\n",
    "                # weight regularization\n",
    "                if cfg.TEST.ADAPTATION.WEIGHT_REG > 0.0: # 이거 안쓰는 것 같음\n",
    "                    stick_loss = 0\n",
    "                    for p_idx, (_p, s) in enumerate(zip(optimizer.param_groups, init_weights)):\n",
    "                        p = _p['params'][0]\n",
    "                        stick_loss += torch.mean((p - s) ** 2)\n",
    "                    losses[\"stick\"] = cfg.TEST.ADAPTATION.WEIGHT_REG * stick_loss\n",
    "                total_loss = sum([losses[k] for k in losses])\n",
    "                #not_redundant = min([feature_sim[k] for k in feature_sim if 'gl' in k]) < cfg.TEST.ADAPTATION.SKIP_THRESHOLD if cfg.TEST.ADAPTATION.SKIP_REDUNDANT else True\n",
    "                #cur_used = losses[\"global_align\"] > div_thr or not_redundant\n",
    "                #cur_used = losses[\"global_align\"] > div_thr or idx % cfg.TEST.ADAPTATION.SKIP_PERIOD == 0\n",
    "                cur_used = False\n",
    "                if cfg.TEST.ADAPTATION.SKIP_REDUNDANT is None:\n",
    "                    cur_used = True\n",
    "                elif 'stat' in cfg.TEST.ADAPTATION.SKIP_REDUNDANT and losses[\"global_align\"] > div_thr:\n",
    "                    cur_used = True\n",
    "                elif 'period' in cfg.TEST.ADAPTATION.SKIP_REDUNDANT and idx % cfg.TEST.ADAPTATION.SKIP_PERIOD == 0:\n",
    "                    cur_used = True\n",
    "                elif 'ema' in cfg.TEST.ADAPTATION.SKIP_REDUNDANT and losses[\"global_align\"] / (loss_ema99 + 1e-7) > cfg.TEST.ADAPTATION.SKIP_BETA:\n",
    "                    cur_used = True\n",
    "                # cur_used = losses[\"global_align\"] / (loss_ema99 + 1e-7) > cfg.TEST.ADAPTATION.SKIP_BETA if cfg.TEST.ADAPTATION.SKIP_REDUNDANT else True\n",
    "                is_used += int(cur_used)\n",
    "                if total_loss > 0 and cur_used:\n",
    "                    total_loss.backward()\n",
    "                    if cfg.SOLVER.CLIP_GRADIENTS.ENABLED:\n",
    "                        torch.nn.utils.clip_grad_norm_(model.backbone.parameters(),\n",
    "                                                       cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE)\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    pause_iter = 1\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                loss_str = \" \".join([\"{}: {:.6f}, \".format(k, losses[k].item()) for k in losses])\n",
    "\n",
    "                if \"global_align\" in losses:\n",
    "                    loss_ema99 = 0.99 * loss_ema99 + 0.01 * losses[\"global_align\"].item()\n",
    "                    loss_ema95 = 0.95 * loss_ema95 + 0.05 * losses[\"global_align\"].item()\n",
    "                    loss_ema90 = 0.9 * loss_ema90 + 0.1 * losses[\"global_align\"].item()\n",
    "                del losses, total_loss\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    outputs = model.inference(inputs)\n",
    "                loss_str = \"\"\n",
    "                pause_iter += 1\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "            total_compute_time += time.perf_counter() - start_compute_time\n",
    "\n",
    "            with torch.no_grad():\n",
    "                evaluator.process(inputs, outputs)\n",
    "\n",
    "            if val_data_loader is not None and idx % 50 == 0:\n",
    "                model.online_adapt = False\n",
    "                val_results, _ = inference_on_dataset(model, val_data_loader, val_evaluator)\n",
    "                if wandb is not None:\n",
    "                    wandb.log({'val-mAP': val_results['bbox']['AP'], 'val-mAP50': val_results['bbox']['AP50']}, step=cur_step)\n",
    "                model.online_adapt = True\n",
    "\n",
    "            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n",
    "            seconds_per_img = total_compute_time / iters_after_start\n",
    "            if idx >= num_warmup * 2 or seconds_per_img > 5:\n",
    "                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n",
    "                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n",
    "                print_str = \"Inference done {}/{}. {:.4f} s / img. ETA={} \".format(\n",
    "                        idx + 1, total, seconds_per_img, str(eta)\n",
    "                    )\n",
    "                print_str += loss_str\n",
    "                print_str += \"lr: {}\".format(optimizer.param_groups[0]['lr'])\n",
    "                log_every_n_seconds(\n",
    "                    logging.INFO,\n",
    "                    print_str,\n",
    "                    n=5,\n",
    "                )\n",
    "\n",
    "    results = evaluator.evaluate(domain_name=domain_name)\n",
    "    # An evaluator may return None when not in main process.\n",
    "    # Replace it by an empty dict instead to make it easier for downstream code to handle\n",
    "\n",
    "    if results is None:\n",
    "        results = {}\n",
    "    return results, loss_ema99, loss_ema95, loss_ema90, is_used, total_compute_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b93d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_continual_domain_shift_discrete(cls, cfg, wandb=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cfg (CfgNode):\n",
    "            evaluators (list[DatasetEvaluator] or None): if None, will call\n",
    "                :meth:`build_evaluator`. Otherwise, must have the same length as\n",
    "                `cfg.DATASETS.TEST`.\n",
    "\n",
    "        Returns:\n",
    "            dict: a dict of result metrics\n",
    "        \"\"\"\n",
    "        results = OrderedDict()\n",
    "        elapsed_time = OrderedDict()\n",
    "        backward_num = OrderedDict()\n",
    "        dataset_name = cfg.DATASETS.TEST[0]\n",
    "        wandb_step = 0\n",
    "        for d_idx, attr in enumerate(['dawn/dusk', 'clear']):\n",
    "        #for d_idx, attr in enumerate(['foggy', 'night']):\n",
    "            if d_idx == 0:\n",
    "                model, optimizer, teacher_model = configure_model(cfg, DefaultTrainer, revert=True)\n",
    "            # d_name = \"{}-clear-{}\".format(dataset_name, attr)\n",
    "            d_name = \"{}-clear-{}\".format(dataset_name, attr) if attr in ['night', 'dawn/dusk'] else \"{}-{}-daytime\".format(dataset_name, attr)\n",
    "            data_loader = cls.build_test_loader(cfg, d_name)\n",
    "            evaluator = cls.build_evaluator(cfg, d_name)\n",
    "            if cfg.TEST.ONLINE_ADAPTATION:\n",
    "                results_i, loss_ema99, loss_ema95, loss_ema90, is_used, total_compute_time = inference_on_dataset_online_adaptation(cfg, model, data_loader, optimizer, evaluator, d_idx, wandb, teacher_model=teacher_model, domain_name=attr)\n",
    "                backward_num[d_name] = is_used\n",
    "            results[d_name] = results_i\n",
    "            elapsed_time[d_name] = total_compute_time\n",
    "\n",
    "            if comm.is_main_process(): # 분산학습 때 내가 rank=0 메인 프로세스인지 확인하는 함수\n",
    "                assert isinstance(\n",
    "                    results_i, dict\n",
    "                ), \"Evaluator must return a dict on the main process. Got {} instead.\".format(\n",
    "                    results_i\n",
    "                )\n",
    "                logger.info(\"Evaluation results for {} in csv format:\".format(d_name))\n",
    "                print_csv_format(results_i) # rank=0의 메인 프로세스의 결과만 출력 | 한 도메인 끝날때마다 출력\n",
    "\n",
    "            mem_str = \"torch.cuda.memory_allocated: %fGB\\n\" % (torch.cuda.memory_allocated(0) / 1024 / 1024 / 1024)\n",
    "            mem_str += \"torch.cuda.max_memory_allocated: %fGB\\n\" % (torch.cuda.max_memory_allocated(0) / 1024 / 1024 / 1024)\n",
    "            mem_str += \"torch.cuda.memory_reserved: %fGB\" % (torch.cuda.memory_reserved(0) / 1024 / 1024 / 1024)\n",
    "            mem_str += \"torch.cuda.max_memory_reserved: %fGB\" % (torch.cuda.max_memory_reserved(0) / 1024 / 1024 / 1024)\n",
    "            print(mem_str)\n",
    "            logger.info(mem_str)\n",
    "        print(backward_num)\n",
    "        logger.info('backward_num:{}'.format(','.join([str(v) for v in list(backward_num.values())])))\n",
    "        print('Elapsed Time')\n",
    "        print(elapsed_time)\n",
    "        logger.info('Elapsed Time: {}'.format(','.join([str(int(v)) for v in list(elapsed_time.values())])))\n",
    "        logger.info('Avg FPS: {:.3f}s'.format(sum(list(elapsed_time.values())) / len(elapsed_time)))\n",
    "        if len(results) == 1:\n",
    "            results = list(results.values())[0]\n",
    "        return results, backward_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9248ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    cfg = setup(args)\n",
    "    res, backward_num = Trainer.test_continual_domain_shift_discrete(cfg, wandb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f613f6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep  7 12:11:38 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   50C    P0              44W / 250W |   4418MiB / 16384MiB |     94%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE-16GB           Off | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              30W / 250W |   4222MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-PCIE-16GB           Off | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   42C    P0              27W / 250W |      8MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P100-PCIE-16GB           Off | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              31W / 250W |   4372MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla P100-PCIE-16GB           Off | 00000000:0C:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              26W / 250W |      6MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla P100-PCIE-16GB           Off | 00000000:0D:00.0 Off |                    0 |\n",
      "| N/A   41C    P0              33W / 250W |    684MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla P100-PCIE-16GB           Off | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              31W / 250W |   1922MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla P100-PCIE-16GB           Off | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              31W / 250W |    914MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eee24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 현재 폴더: ptta/other_method/DUA/\n",
    "# ptta 바로 위의 디렉토리를 sys.path에 추가\n",
    "PROJECT_PARENT = Path.cwd().parents[1]  # -> ptta/ 의 부모 디렉토리\n",
    "sys.path.insert(0, str(PROJECT_PARENT))\n",
    "\n",
    "from os import path\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ttadapters.datasets import BaseDataset, DatasetHolder, DataLoaderHolder\n",
    "from ttadapters.datasets import SHIFTClearDatasetForObjectDetection, SHIFTCorruptedDatasetForObjectDetection, SHIFTDiscreteSubsetForObjectDetection\n",
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "\n",
    "from supervision.metrics.mean_average_precision import MeanAveragePrecision\n",
    "from supervision.detection.core import Detections\n",
    "\n",
    "# import wandb\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import RTDetrForObjectDetection, RTDetrImageProcessorFast, RTDetrConfig\n",
    "from transformers.image_utils import AnnotationFormat\n",
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6aa8a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using device - cuda:2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# Set CUDA Device Number 0~7\n",
    "DEVICE_NUM = 2\n",
    "ADDITIONAL_GPU = 0\n",
    "DATA_TYPE = torch.bfloat16\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if ADDITIONAL_GPU:\n",
    "        torch.cuda.set_device(DEVICE_NUM)\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{DEVICE_NUM}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DEVICE_NUM = -1\n",
    "\n",
    "print(f\"INFO: Using device - {device}\" + (f\":{DEVICE_NUM}\" if ADDITIONAL_GPU else \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069aba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_model_id = \"PekingU/rtdetr_r50vd\"\n",
    "\n",
    "# Load the reference model configuration\n",
    "reference_config = RTDetrConfig.from_pretrained(reference_model_id, torch_dtype=torch.float32, return_dict=True)\n",
    "reference_config.num_labels = 6\n",
    "\n",
    "# Set the image size and preprocessor size\n",
    "reference_config.image_size = 800\n",
    "\n",
    "# Load the reference model image processor\n",
    "reference_preprocessor = RTDetrImageProcessorFast.from_pretrained(reference_model_id)\n",
    "reference_preprocessor.format = AnnotationFormat.COCO_DETECTION  # COCO Format / Detection BBOX Format\n",
    "reference_preprocessor.size = {\"height\": 800, \"width\": 800}\n",
    "reference_preprocessor.do_resize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2e975a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrained = RTDetrForObjectDetection(config=reference_config)\n",
    "model_states = load_file(\"/home/elicer/ptta/RT-DETR_R50vd_SHIFT_CLEAR.safetensors\", device=\"cpu\")\n",
    "model_pretrained.load_state_dict(model_states, strict=False)\n",
    "\n",
    "for param in model_pretrained.parameters():\n",
    "    param.requires_grad = False  # Freeze\n",
    "\n",
    "# Initialize Model\n",
    "model_pretrained.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c70bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Callable\n",
    "\n",
    "class SHIFTCorruptedTaskDatasetForObjectDetection(SHIFTDiscreteSubsetForObjectDetection):\n",
    "    def __init__(\n",
    "            self, root: str, force_download: bool = False,\n",
    "            train: bool = True, valid: bool = False,\n",
    "            transform: Optional[Callable] = None, task: str = \"clear\", target_transform: Optional[Callable] = None\n",
    "    ):\n",
    "        super().__init__(\n",
    "            root=root, force_download=force_download,\n",
    "            train=train, valid=valid, subset_type=task_to_subset_types(task),\n",
    "            transform=transform, target_transform=target_transform\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c069e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SHIFTCorruptedTaskDatasetForObjectDetection(root=DATA_ROOT, train=True, valid=True, task=task)\n",
    "\n",
    "raw_data = DataLoader(LabelDataset(dataset), batch_size=batch_size, collate_fn=naive_collate_fn)\n",
    "dataloader_discrete = DataLoader(DatasetAdapterForTransformers(dataset), batch_size=batch_size, collate_fn=partial(collate_fn, preprocessor=reference_preprocessor))\n",
    "for idx, lables, inputs in zip(tqdm(range(len(raw_data))), raw_data, dataloader_discrete):\n",
    "    sizes = [label['orig_size'].cpu().tolist() for label in inputs['labels']]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(pixel_values=inputs['pixel_values'].to(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttadapters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
