{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RT-DETR Pretraining with SHIFT-Discrete Dataset"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:41:39.278477Z",
     "start_time": "2025-06-26T01:41:39.275962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = \"expandable_segments:True\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T01:41:46.249649Z",
     "start_time": "2025-06-26T01:41:41.700024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from os import path\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from ttadapters.datasets import BaseDataset, DatasetHolder, DataLoaderHolder\n",
    "from ttadapters.datasets import SHIFTDiscreteDatasetForObjectDetection\n",
    "from transformers import Trainer, TrainingArguments, DefaultDataCollator, EarlyStoppingCallback\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check GPU Availability"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:12:35.625927Z",
     "start_time": "2025-06-26T02:12:35.416092Z"
    }
   },
   "cell_type": "code",
   "source": "!nvidia-smi",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 26 11:12:35 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 550.144.03             Driver Version: 550.144.03     CUDA Version: 12.4     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 4070 ...    Off |   00000000:01:00.0 Off |                  N/A |\r\n",
      "|  0%   39C    P8             15W /  285W |     931MiB /  16376MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|    0   N/A  N/A      1723      G   /usr/lib/xorg/Xorg                              4MiB |\r\n",
      "|    0   N/A  N/A    173669      C   ...charm_project_716/.venv/bin/python3        916MiB |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:12:38.299582Z",
     "start_time": "2025-06-26T02:12:38.297291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set CUDA Device Number 0~7\n",
    "DEVICE_NUM = 0\n",
    "ADDITIONAL_GPU = 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if ADDITIONAL_GPU:\n",
    "        torch.cuda.set_device(DEVICE_NUM)\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{DEVICE_NUM}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DEVICE_NUM = -1\n",
    "\n",
    "print(f\"INFO: Using device - {device}\" + (f\":{DEVICE_NUM}\" if ADDITIONAL_GPU else \"\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using device - cuda:0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Dataset"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:12:43.595633Z",
     "start_time": "2025-06-26T02:12:39.365544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_ROOT = path.join(\".\", \"data\")\n",
    "\n",
    "dataset = DatasetHolder(\n",
    "    train=SHIFTDiscreteDatasetForObjectDetection(root=DATA_ROOT, train=True),\n",
    "    valid=SHIFTDiscreteDatasetForObjectDetection(root=DATA_ROOT, valid=True)\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06/26/2025 11:12:39] SHIFT DevKit - INFO - Base: ./data/SHIFT/discrete/images/train. Backend: <shift_dev.utils.backend.ZipBackend object at 0x75b4c2008cd0>\n",
      "[06/26/2025 11:12:39] SHIFT DevKit - INFO - Loading annotation from './data/SHIFT/discrete/images/train/front/det_2d.json' ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Downloading 'SHIFT' from file server to ./data/SHIFT/discrete...\n",
      "INFO: Dataset archive found in the root directory. Skipping download.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06/26/2025 11:12:40] SHIFT DevKit - INFO - Loading annotation from './data/SHIFT/discrete/images/train/front/det_2d.json' Done.\n",
      "[06/26/2025 11:12:42] SHIFT DevKit - INFO - Loading annotation takes 3.35 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "\n",
      "Item                 Shape                               Min        Max       \n",
      "--------------------------------------------------------------------------------\n",
      "original_hw          [tensor([800]), tensor([1280])]\n",
      "input_hw             [tensor([800]), tensor([1280])]\n",
      "frame_ids            torch.Size([1])                           0.00       0.00\n",
      "name                 ['00000000_img_front.jpg']\n",
      "videoName            ['0016-1b62']\n",
      "intrinsics           torch.Size([1, 3, 3])                     0.00     640.00\n",
      "extrinsics           torch.Size([1, 4, 4])                    -7.53     219.91\n",
      "boxes2d              torch.Size([1, 26, 4])                    5.00     974.00\n",
      "boxes2d_classes      torch.Size([1, 26])                       0.00       3.00\n",
      "boxes2d_track_ids    torch.Size([1, 26])                       0.00      25.00\n",
      "images               torch.Size([1, 1, 3, 800, 1280])          0.00     255.00\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06/26/2025 11:12:43] SHIFT DevKit - INFO - Base: ./data/SHIFT/discrete/images/val. Backend: <shift_dev.utils.backend.ZipBackend object at 0x75b4c2008cd0>\n",
      "[06/26/2025 11:12:43] SHIFT DevKit - INFO - Loading annotation from './data/SHIFT/discrete/images/val/front/det_2d.json' ...\n",
      "[06/26/2025 11:12:43] SHIFT DevKit - INFO - Loading annotation from './data/SHIFT/discrete/images/val/front/det_2d.json' Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video name: 0016-1b62\n",
      "Sample indices within a video: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "INFO: Downloading 'SHIFT' from file server to ./data/SHIFT/discrete...\n",
      "INFO: Dataset archive found in the root directory. Skipping download.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[06/26/2025 11:12:43] SHIFT DevKit - INFO - Loading annotation takes 0.24 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "\n",
      "Item                 Shape                               Min        Max       \n",
      "--------------------------------------------------------------------------------\n",
      "original_hw          [tensor([800]), tensor([1280])]\n",
      "input_hw             [tensor([800]), tensor([1280])]\n",
      "frame_ids            torch.Size([1])                           0.00       0.00\n",
      "name                 ['00000000_img_front.jpg']\n",
      "videoName            ['0116-4859']\n",
      "intrinsics           torch.Size([1, 3, 3])                     0.00     640.00\n",
      "extrinsics           torch.Size([1, 4, 4])                    -0.90     138.34\n",
      "boxes2d              torch.Size([1, 6, 4])                   246.00     859.00\n",
      "boxes2d_classes      torch.Size([1, 6])                        1.00       5.00\n",
      "boxes2d_track_ids    torch.Size([1, 6])                        0.00       5.00\n",
      "images               torch.Size([1, 1, 3, 800, 1280])          0.00     255.00\n",
      "\n",
      "Video name: 0116-4859\n",
      "Sample indices within a video: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "INFO: Dataset loaded successfully. Number of samples - Train: 20800, Valid: 2800\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:00.684463Z",
     "start_time": "2025-06-26T02:13:00.669429Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.train[1]['front'].keys()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['original_hw', 'input_hw', 'frame_ids', 'name', 'videoName', 'intrinsics', 'extrinsics', 'boxes2d', 'boxes2d_classes', 'boxes2d_track_ids', 'images'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:01.300775Z",
     "start_time": "2025-06-26T02:13:01.284293Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.train[999]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'front': {'original_hw': (800, 1280),\n",
       "  'input_hw': (800, 1280),\n",
       "  'frame_ids': 490,\n",
       "  'name': '00000490_img_front.jpg',\n",
       "  'videoName': '0c9d-eefc',\n",
       "  'intrinsics': tensor([[640.,   0., 640.],\n",
       "          [  0., 640., 400.],\n",
       "          [  0.,   0.,   1.]]),\n",
       "  'extrinsics': tensor([[-5.7429e-01,  7.7804e-01, -2.5465e-01,  1.6100e+02],\n",
       "          [-7.0979e-01, -6.2821e-01, -3.1867e-01, -2.0023e+01],\n",
       "          [-4.0791e-01, -2.2626e-03,  9.1302e-01,  1.5929e+00],\n",
       "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]]),\n",
       "  'boxes2d': tensor([[ 457.,  405.,  525.,  467.],\n",
       "          [ 599.,  391.,  612.,  403.],\n",
       "          [ 599.,  398.,  677.,  459.],\n",
       "          [ 835.,  391., 1280.,  605.],\n",
       "          [ 655.,  396.,  668.,  402.],\n",
       "          [ 392.,  394.,  404.,  401.],\n",
       "          [ 665.,  396.,  676.,  402.],\n",
       "          [ 842.,  390.,  848.,  397.],\n",
       "          [1207.,  380., 1217.,  399.]]),\n",
       "  'boxes2d_classes': tensor([1, 2, 1, 1, 1, 2, 1, 0, 0]),\n",
       "  'boxes2d_track_ids': tensor([ 4,  1,  0,  8, 14, 10, 13, 15,  9]),\n",
       "  'images': tensor([[[[133., 133., 133.,  ..., 125., 124., 123.],\n",
       "            [135., 135., 135.,  ..., 125., 124., 123.],\n",
       "            [140., 140., 139.,  ..., 125., 123., 122.],\n",
       "            ...,\n",
       "            [199., 202., 205.,  ..., 208., 211., 213.],\n",
       "            [204., 205., 206.,  ..., 206., 208., 209.],\n",
       "            [208., 208., 206.,  ..., 205., 205., 204.]],\n",
       "  \n",
       "           [[152., 152., 152.,  ..., 153., 152., 151.],\n",
       "            [154., 154., 154.,  ..., 153., 152., 151.],\n",
       "            [157., 157., 156.,  ..., 152., 151., 150.],\n",
       "            ...,\n",
       "            [190., 193., 196.,  ..., 194., 196., 198.],\n",
       "            [195., 196., 197.,  ..., 192., 193., 194.],\n",
       "            [200., 200., 197.,  ..., 191., 190., 189.]],\n",
       "  \n",
       "           [[169., 169., 169.,  ..., 175., 174., 173.],\n",
       "            [171., 171., 171.,  ..., 175., 174., 173.],\n",
       "            [173., 173., 172.,  ..., 173., 173., 172.],\n",
       "            ...,\n",
       "            [175., 178., 181.,  ..., 185., 191., 193.],\n",
       "            [178., 179., 180.,  ..., 183., 188., 189.],\n",
       "            [181., 181., 180.,  ..., 182., 185., 184.]]]])}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:02.007926Z",
     "start_time": "2025-06-26T02:13:01.993083Z"
    }
   },
   "cell_type": "code",
   "source": "dataset.train[1000]['front']['images'].shape  # should be (batch_size, num_channels, height, width)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 800, 1280])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## DataLoader"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:07.259218Z",
     "start_time": "2025-06-26T02:13:07.257201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set Batch Size\n",
    "BATCH_SIZE = 32, 20, 32\n",
    "\n",
    "# Dataset Configs\n",
    "CLASSES = dataset.train.classes\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "\n",
    "print(f\"INFO: Set batch size - Train: {BATCH_SIZE[0]}, Valid: {BATCH_SIZE[1]}, Test: {BATCH_SIZE[2]}\")\n",
    "print(f\"INFO: Number of classes - {NUM_CLASSES} {CLASSES}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Set batch size - Train: 32, Valid: 20, Test: 32\n",
      "INFO: Number of classes - 6 ['pedestrian', 'car', 'truck', 'bus', 'motorcycle', 'bicycle']\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:09.327721Z",
     "start_time": "2025-06-26T02:13:09.324399Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DatasetAdapterForTransformers(BaseDataset):\n",
    "    def __init__(self, original_dataset, camera='front'):\n",
    "        self.dataset = original_dataset\n",
    "        self.camera = camera\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx][self.camera]\n",
    "        image = item['images'].squeeze(0)\n",
    "\n",
    "        # Convert to COCO_Detection Format\n",
    "        annotations = []\n",
    "        target = dict(image_id=idx, annotations=annotations)\n",
    "        for box, cls in zip(item['boxes2d'], item['boxes2d_classes']):\n",
    "            x1, y1, x2, y2 = box.tolist()\n",
    "            width, height = x2 - x1, y2 - y1\n",
    "            annotations.append(dict(\n",
    "                bbox=[x1, y1, width, height],  # COCO format: [x, y, width, height]\n",
    "                category_id=cls.item(),\n",
    "                area=width * height,\n",
    "                iscrowd=0\n",
    "            ))\n",
    "\n",
    "        # Following prepare_coco_detection_annotation's expected format\n",
    "        # But, RT-DETR ImageProcessor eventually re-converts the bbox to (x1, y1, x2, y2) format\n",
    "        return dict(image=image, target=target)"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:10.194045Z",
     "start_time": "2025-06-26T02:13:10.191719Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collate_fn(batch, preprocessor=None):\n",
    "    images = [item['image'] for item in batch]\n",
    "    if preprocessor is not None:\n",
    "        target = [item['target'] for item in batch]\n",
    "        return preprocessor(images=images, annotations=target, return_tensors=\"pt\")\n",
    "    else:\n",
    "        # If no preprocessor is provided, just assume images are already in tensor format\n",
    "        return dict(\n",
    "            pixel_values=dict(pixel_values=torch.stack(images)),\n",
    "            labels=[dict(\n",
    "                class_labels=item['boxes2d_classes'].long(),\n",
    "                boxes=item[\"boxes2d\"].float()\n",
    "            ) for item in batch]\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:11.913052Z",
     "start_time": "2025-06-26T02:13:11.851216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import RTDetrForObjectDetection, RTDetrImageProcessorFast, RTDetrConfig\n",
    "from transformers.image_utils import AnnotationFormat"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:13.081178Z",
     "start_time": "2025-06-26T02:13:12.570334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reference_model_id = \"PekingU/rtdetr_r50vd\"\n",
    "\n",
    "# Load the reference model configuration\n",
    "reference_config = RTDetrConfig.from_pretrained(reference_model_id)\n",
    "reference_config.num_labels = NUM_CLASSES\n",
    "\n",
    "# Load the reference model image processor\n",
    "reference_preprocessor = RTDetrImageProcessorFast.from_pretrained(reference_model_id)\n",
    "reference_preprocessor.format = AnnotationFormat.COCO_DETECTION  # COCO Format / Detection BBOX Format"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:13.781655Z",
     "start_time": "2025-06-26T02:13:13.319963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = RTDetrForObjectDetection(config=reference_config)\n",
    "\n",
    "if ADDITIONAL_GPU:\n",
    "    model = nn.DataParallel(model, device_ids=list(range(DEVICE_NUM, DEVICE_NUM+ADDITIONAL_GPU+1)))\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RTDetrForObjectDetection(\n",
       "  (model): RTDetrModel(\n",
       "    (backbone): RTDetrConvEncoder(\n",
       "      (model): RTDetrResNetBackbone(\n",
       "        (embedder): RTDetrResNetEmbeddings(\n",
       "          (embedder): Sequential(\n",
       "            (0): RTDetrResNetConvLayer(\n",
       "              (convolution): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (normalization): RTDetrFrozenBatchNorm2d()\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (1): RTDetrResNetConvLayer(\n",
       "              (convolution): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (normalization): RTDetrFrozenBatchNorm2d()\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (2): RTDetrResNetConvLayer(\n",
       "              (convolution): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (normalization): RTDetrFrozenBatchNorm2d()\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "          )\n",
       "          (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (encoder): RTDetrResNetEncoder(\n",
       "          (stages): ModuleList(\n",
       "            (0): RTDetrResNetStage(\n",
       "              (layers): Sequential(\n",
       "                (0): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): RTDetrResNetShortCut(\n",
       "                    (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                  )\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RTDetrResNetStage(\n",
       "              (layers): Sequential(\n",
       "                (0): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Sequential(\n",
       "                    (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                    (1): RTDetrResNetShortCut(\n",
       "                      (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                    )\n",
       "                  )\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (3): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RTDetrResNetStage(\n",
       "              (layers): Sequential(\n",
       "                (0): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Sequential(\n",
       "                    (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                    (1): RTDetrResNetShortCut(\n",
       "                      (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                    )\n",
       "                  )\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (3): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (4): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (5): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RTDetrResNetStage(\n",
       "              (layers): Sequential(\n",
       "                (0): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Sequential(\n",
       "                    (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "                    (1): RTDetrResNetShortCut(\n",
       "                      (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                    )\n",
       "                  )\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (1): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "                (2): RTDetrResNetBottleNeckLayer(\n",
       "                  (shortcut): Identity()\n",
       "                  (layer): Sequential(\n",
       "                    (0): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (1): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): ReLU()\n",
       "                    )\n",
       "                    (2): RTDetrResNetConvLayer(\n",
       "                      (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                      (normalization): RTDetrFrozenBatchNorm2d()\n",
       "                      (activation): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (activation): ReLU()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (encoder_input_proj): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder): RTDetrHybridEncoder(\n",
       "      (encoder): ModuleList(\n",
       "        (0): RTDetrEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0): RTDetrEncoderLayer(\n",
       "              (self_attn): RTDetrMultiheadAttention(\n",
       "                (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (activation_fn): GELUActivation()\n",
       "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (lateral_convs): ModuleList(\n",
       "        (0-1): 2 x RTDetrConvNormLayer(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (fpn_blocks): ModuleList(\n",
       "        (0-1): 2 x RTDetrCSPRepLayer(\n",
       "          (conv1): RTDetrConvNormLayer(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLU()\n",
       "          )\n",
       "          (conv2): RTDetrConvNormLayer(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLU()\n",
       "          )\n",
       "          (bottlenecks): Sequential(\n",
       "            (0): RTDetrRepVggBlock(\n",
       "              (conv1): RTDetrConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (conv2): RTDetrConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (activation): SiLU()\n",
       "            )\n",
       "            (1): RTDetrRepVggBlock(\n",
       "              (conv1): RTDetrConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (conv2): RTDetrConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (activation): SiLU()\n",
       "            )\n",
       "            (2): RTDetrRepVggBlock(\n",
       "              (conv1): RTDetrConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (conv2): RTDetrConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (conv3): Identity()\n",
       "        )\n",
       "      )\n",
       "      (downsample_convs): ModuleList(\n",
       "        (0-1): 2 x RTDetrConvNormLayer(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (pan_blocks): ModuleList(\n",
       "        (0-1): 2 x RTDetrCSPRepLayer(\n",
       "          (conv1): RTDetrConvNormLayer(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLU()\n",
       "          )\n",
       "          (conv2): RTDetrConvNormLayer(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): SiLU()\n",
       "          )\n",
       "          (bottlenecks): Sequential(\n",
       "            (0): RTDetrRepVggBlock(\n",
       "              (conv1): RTDetrConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (conv2): RTDetrConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (activation): SiLU()\n",
       "            )\n",
       "            (1): RTDetrRepVggBlock(\n",
       "              (conv1): RTDetrConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (conv2): RTDetrConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (activation): SiLU()\n",
       "            )\n",
       "            (2): RTDetrRepVggBlock(\n",
       "              (conv1): RTDetrConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (conv2): RTDetrConvNormLayer(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (activation): Identity()\n",
       "              )\n",
       "              (activation): SiLU()\n",
       "            )\n",
       "          )\n",
       "          (conv3): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (denoising_class_embed): Embedding(7, 256, padding_idx=6)\n",
       "    (enc_output): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (enc_score_head): Linear(in_features=256, out_features=6, bias=True)\n",
       "    (enc_bbox_head): RTDetrMLPPredictionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder_input_proj): ModuleList(\n",
       "      (0-2): 3 x Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): RTDetrDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x RTDetrDecoderLayer(\n",
       "          (self_attn): RTDetrMultiheadAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): RTDetrMultiscaleDeformableAttention(\n",
       "            (attn): MultiScaleDeformableAttention()\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=96, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (query_pos_head): RTDetrMLPPredictionHead(\n",
       "        (layers): ModuleList(\n",
       "          (0): Linear(in_features=4, out_features=512, bias=True)\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (class_embed): ModuleList(\n",
       "        (0-5): 6 x Linear(in_features=256, out_features=6, bias=True)\n",
       "      )\n",
       "      (bbox_embed): ModuleList(\n",
       "        (0-5): 6 x RTDetrMLPPredictionHead(\n",
       "          (layers): ModuleList(\n",
       "            (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "            (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (class_embed): ModuleList(\n",
       "    (0-5): 6 x Linear(in_features=256, out_features=6, bias=True)\n",
       "  )\n",
       "  (bbox_embed): ModuleList(\n",
       "    (0-5): 6 x RTDetrMLPPredictionHead(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:13.910487Z",
     "start_time": "2025-06-26T02:13:13.893132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_d = DatasetAdapterForTransformers(dataset.train)[5]\n",
    "test_d"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': tensor([[[ 64.,  65.,  67.,  ..., 121., 121., 121.],\n",
       "          [ 62.,  61.,  64.,  ..., 121., 121., 121.],\n",
       "          [ 58.,  60.,  61.,  ..., 121., 121., 121.],\n",
       "          ...,\n",
       "          [105., 105., 105.,  ...,  60.,  64.,  72.],\n",
       "          [103., 103., 103.,  ...,  67.,  67.,  67.],\n",
       "          [100., 100., 100.,  ...,  76.,  72.,  66.]],\n",
       " \n",
       "         [[ 27.,  26.,  26.,  ..., 139., 139., 139.],\n",
       "          [ 25.,  24.,  22.,  ..., 139., 139., 139.],\n",
       "          [ 22.,  23.,  22.,  ..., 139., 139., 139.],\n",
       "          ...,\n",
       "          [106., 106., 106.,  ...,  59.,  63.,  71.],\n",
       "          [104., 104., 104.,  ...,  66.,  66.,  66.],\n",
       "          [101., 101., 101.,  ...,  75.,  71.,  65.]],\n",
       " \n",
       "         [[  9.,   9.,   8.,  ..., 153., 153., 153.],\n",
       "          [  7.,   6.,   6.,  ..., 153., 153., 153.],\n",
       "          [  6.,   7.,   7.,  ..., 153., 153., 153.],\n",
       "          ...,\n",
       "          [111., 111., 111.,  ...,  65.,  69.,  77.],\n",
       "          [109., 109., 109.,  ...,  72.,  72.,  72.],\n",
       "          [106., 106., 106.,  ...,  81.,  77.,  71.]]]),\n",
       " 'target': {'image_id': 5,\n",
       "  'annotations': [{'bbox': [593.0, 396.0, 22.0, 21.0],\n",
       "    'category_id': 3,\n",
       "    'area': 462.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [126.0, 404.0, 14.0, 7.0],\n",
       "    'category_id': 1,\n",
       "    'area': 98.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [633.0, 402.0, 24.0, 18.0],\n",
       "    'category_id': 1,\n",
       "    'area': 432.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [75.0, 402.0, 6.0, 9.0],\n",
       "    'category_id': 1,\n",
       "    'area': 54.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [486.0, 408.0, 51.0, 46.0],\n",
       "    'category_id': 1,\n",
       "    'area': 2346.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [78.0, 407.0, 359.0, 165.0],\n",
       "    'category_id': 1,\n",
       "    'area': 59235.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [699.0, 396.0, 10.0, 27.0],\n",
       "    'category_id': 0,\n",
       "    'area': 270.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [675.0, 398.0, 8.0, 18.0],\n",
       "    'category_id': 0,\n",
       "    'area': 144.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [803.0, 389.0, 21.0, 66.0],\n",
       "    'category_id': 0,\n",
       "    'area': 1386.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [134.0, 381.0, 37.0, 80.0],\n",
       "    'category_id': 0,\n",
       "    'area': 2960.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [432.0, 393.0, 15.0, 42.0],\n",
       "    'category_id': 0,\n",
       "    'area': 630.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [738.0, 409.0, 7.0, 21.0],\n",
       "    'category_id': 0,\n",
       "    'area': 147.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [712.0, 406.0, 8.0, 23.0],\n",
       "    'category_id': 0,\n",
       "    'area': 184.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [878.0, 381.0, 50.0, 105.0],\n",
       "    'category_id': 0,\n",
       "    'area': 5250.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [684.0, 395.0, 10.0, 29.0],\n",
       "    'category_id': 0,\n",
       "    'area': 290.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [932.0, 364.0, 99.0, 190.0],\n",
       "    'category_id': 0,\n",
       "    'area': 18810.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [508.0, 394.0, 14.0, 14.0],\n",
       "    'category_id': 0,\n",
       "    'area': 196.0,\n",
       "    'iscrowd': 0},\n",
       "   {'bbox': [555.0, 398.0, 8.0, 20.0],\n",
       "    'category_id': 0,\n",
       "    'area': 160.0,\n",
       "    'iscrowd': 0}]}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:14.467612Z",
     "start_time": "2025-06-26T02:13:14.449935Z"
    }
   },
   "cell_type": "code",
   "source": "reference_preprocessor(images=test_d['image'], annotations=test_d['target'])",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pixel_values': tensor([[[[0.2514, 0.2654, 0.2874,  ..., 0.4745, 0.4745, 0.4745],\n",
       "          [0.2384, 0.2522, 0.2799,  ..., 0.4745, 0.4745, 0.4745],\n",
       "          [0.2345, 0.2456, 0.2704,  ..., 0.4768, 0.4768, 0.4768],\n",
       "          ...,\n",
       "          [0.4108, 0.4118, 0.4114,  ..., 0.2585, 0.2519, 0.2749],\n",
       "          [0.4072, 0.4083, 0.4117,  ..., 0.2805, 0.2562, 0.2625],\n",
       "          [0.3951, 0.3963, 0.4037,  ..., 0.3235, 0.2901, 0.2716]],\n",
       "\n",
       "         [[0.1014, 0.0963, 0.1000,  ..., 0.5451, 0.5451, 0.5451],\n",
       "          [0.0919, 0.0887, 0.0952,  ..., 0.5451, 0.5451, 0.5451],\n",
       "          [0.0912, 0.0901, 0.0929,  ..., 0.5474, 0.5474, 0.5474],\n",
       "          ...,\n",
       "          [0.4147, 0.4157, 0.4154,  ..., 0.2545, 0.2480, 0.2710],\n",
       "          [0.4111, 0.4123, 0.4156,  ..., 0.2766, 0.2522, 0.2586],\n",
       "          [0.3990, 0.4002, 0.4076,  ..., 0.3196, 0.2862, 0.2676]],\n",
       "\n",
       "         [[0.0324, 0.0304, 0.0396,  ..., 0.6000, 0.6000, 0.6000],\n",
       "          [0.0254, 0.0253, 0.0359,  ..., 0.6000, 0.6000, 0.6000],\n",
       "          [0.0317, 0.0325, 0.0364,  ..., 0.6023, 0.6023, 0.6023],\n",
       "          ...,\n",
       "          [0.4343, 0.4353, 0.4350,  ..., 0.2781, 0.2715, 0.2945],\n",
       "          [0.4307, 0.4319, 0.4353,  ..., 0.3001, 0.2758, 0.2821],\n",
       "          [0.4186, 0.4199, 0.4272,  ..., 0.3431, 0.3097, 0.2912]]]]), 'labels': [{'size': torch.Size([640, 640]), 'image_id': tensor([5]), 'class_labels': tensor([3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'boxes': tensor([[0.4719, 0.5081, 0.0172, 0.0262],\n",
       "        [0.1039, 0.5094, 0.0109, 0.0088],\n",
       "        [0.5039, 0.5137, 0.0188, 0.0225],\n",
       "        [0.0609, 0.5081, 0.0047, 0.0113],\n",
       "        [0.3996, 0.5387, 0.0398, 0.0575],\n",
       "        [0.2012, 0.6119, 0.2805, 0.2062],\n",
       "        [0.5500, 0.5119, 0.0078, 0.0337],\n",
       "        [0.5305, 0.5088, 0.0063, 0.0225],\n",
       "        [0.6355, 0.5275, 0.0164, 0.0825],\n",
       "        [0.1191, 0.5263, 0.0289, 0.1000],\n",
       "        [0.3434, 0.5175, 0.0117, 0.0525],\n",
       "        [0.5793, 0.5244, 0.0055, 0.0262],\n",
       "        [0.5594, 0.5219, 0.0063, 0.0287],\n",
       "        [0.7055, 0.5419, 0.0391, 0.1312],\n",
       "        [0.5383, 0.5119, 0.0078, 0.0363],\n",
       "        [0.7668, 0.5738, 0.0773, 0.2375],\n",
       "        [0.4023, 0.5012, 0.0109, 0.0175],\n",
       "        [0.4367, 0.5100, 0.0063, 0.0250]]), 'area': tensor([1.8480e+02, 3.9200e+01, 1.7280e+02, 2.1600e+01, 9.3840e+02, 2.3694e+04,\n",
       "        1.0800e+02, 5.7600e+01, 5.5440e+02, 1.1840e+03, 2.5200e+02, 5.8800e+01,\n",
       "        7.3600e+01, 2.1000e+03, 1.1600e+02, 7.5240e+03, 7.8400e+01, 6.4000e+01]), 'iscrowd': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'orig_size': tensor([ 800, 1280])}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:15.457476Z",
     "start_time": "2025-06-26T02:13:15.441932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "\n",
    "def compute_coco_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    coco_gt = COCO()  # ground truth\n",
    "    coco_dt = coco_gt.loadRes(predictions)  # predictions\n",
    "\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    return {\n",
    "        'mAP@0.95': coco_eval.stats[0],\n",
    "        'mAP@0.5': coco_eval.stats[1],\n",
    "        'mAP@0.75': coco_eval.stats[2],\n",
    "        'mAP_small': coco_eval.stats[3],\n",
    "        'mAP_medium': coco_eval.stats[4],\n",
    "        'mAP_large': coco_eval.stats[5],\n",
    "        'AR@1': coco_eval.stats[6],\n",
    "        'AR@10': coco_eval.stats[7],\n",
    "        'AR@100': coco_eval.stats[8],\n",
    "        'AR_small': coco_eval.stats[9],\n",
    "        'AR_medium': coco_eval.stats[10],\n",
    "        'AR_large': coco_eval.stats[11],\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:23.524374Z",
     "start_time": "2025-06-26T02:13:23.522751Z"
    }
   },
   "cell_type": "code",
   "source": "archived = []",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:24.773619Z",
     "start_time": "2025-06-26T02:13:24.210031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchmetrics.detection import MeanAveragePrecision\n",
    "\n",
    "def compute_coco_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    archived.append(predictions)\n",
    "    archived.append(labels)\n",
    "\n",
    "    # torchmetrics MeanAveragePrecision 객체 생성\n",
    "    # COCO와 동일한 설정\n",
    "    metric = MeanAveragePrecision(\n",
    "        box_format='cxcywh',  # RT-DETR는 center format 사용\n",
    "        iou_type='bbox',\n",
    "        iou_thresholds=None,  # COCO 기본값 사용 (0.5:0.05:0.95)\n",
    "        rec_thresholds=None,  # COCO 기본값 사용\n",
    "        max_detection_thresholds=[1, 10, 100],  # COCO 기본값\n",
    "        class_metrics=False,  # 전체 평균만 계산\n",
    "        sync_on_compute=True\n",
    "    )\n",
    "\n",
    "    # predictions와 labels를 torchmetrics 형식으로 변환\n",
    "    preds = []\n",
    "    targets = []\n",
    "\n",
    "    for i, (pred, label) in enumerate(zip(predictions, labels)):\n",
    "        # predictions 처리 (RT-DETR 출력에 맞게 조정 필요)\n",
    "        # RT-DETR 출력 형식: logits, pred_boxes\n",
    "        if isinstance(pred, dict):\n",
    "            # 모델 출력에서 boxes, scores, labels 추출\n",
    "            pred_dict = {\n",
    "                'boxes': pred.get('pred_boxes', torch.empty(0, 4)),\n",
    "                'scores': pred.get('scores', torch.empty(0)),\n",
    "                'labels': pred.get('labels', torch.empty(0, dtype=torch.long))\n",
    "            }\n",
    "        else:\n",
    "            # 임시 빈 예측 (실제로는 RT-DETR 출력 파싱 필요)\n",
    "            pred_dict = {\n",
    "                'boxes': torch.empty(0, 4),\n",
    "                'scores': torch.empty(0),\n",
    "                'labels': torch.empty(0, dtype=torch.long)\n",
    "            }\n",
    "\n",
    "        # labels 처리 (이미 올바른 형식으로 되어 있음)\n",
    "        if isinstance(label, dict):\n",
    "            target_dict = {\n",
    "                'boxes': label.get('boxes', torch.empty(0, 4)),\n",
    "                'labels': label.get('class_labels', torch.empty(0, dtype=torch.long))\n",
    "            }\n",
    "        else:\n",
    "            target_dict = {\n",
    "                'boxes': torch.empty(0, 4),\n",
    "                'labels': torch.empty(0, dtype=torch.long)\n",
    "            }\n",
    "\n",
    "    preds.append(pred_dict)\n",
    "    targets.append(target_dict)\n",
    "\n",
    "    metric.update(preds, targets)\n",
    "    result = metric.compute()\n",
    "\n",
    "    return {\n",
    "        'mAP@0.95': result['map'].item(),           # mAP @ IoU=0.50:0.95\n",
    "        'mAP@0.5': result['map_50'].item(),         # mAP @ IoU=0.50\n",
    "        'mAP@0.75': result['map_75'].item(),        # mAP @ IoU=0.75\n",
    "        'mAP_small': result['map_small'].item(),    # mAP for small objects\n",
    "        'mAP_medium': result['map_medium'].item(),  # mAP for medium objects\n",
    "        'mAP_large': result['map_large'].item(),    # mAP for large objects\n",
    "        'AR@1': result['mar_1'].item(),             # AR given 1 detection per image\n",
    "        'AR@10': result['mar_10'].item(),           # AR given 10 detections per image\n",
    "        'AR@100': result['mar_100'].item(),         # AR given 100 detections per image\n",
    "        'AR_small': result['mar_small'].item(),     # AR for small objects\n",
    "        'AR_medium': result['mar_medium'].item(),   # AR for medium objects\n",
    "        'AR_large': result['mar_large'].item(),     # AR for large objects\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:28.743944Z",
     "start_time": "2025-06-26T02:13:28.726715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set Epoch Count & Learning Rate\n",
    "EPOCHS = 15\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    warmup_ratio=0.1,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE[0],\n",
    "    per_device_eval_batch_size=BATCH_SIZE[1],\n",
    "    eval_accumulation_steps=BATCH_SIZE[1],\n",
    "    remove_unused_columns=False,\n",
    "    optim=\"adamw_torch\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    save_total_limit=10,\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    #metric_for_best_model=\"mAP@0.95\",\n",
    "    #greater_is_better=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    #report_to=\"wandb\",\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir=\"./logs\",\n",
    "    fp16=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T02:13:30.833331Z",
     "start_time": "2025-06-26T02:13:30.796464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from functools import partial\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=DatasetAdapterForTransformers(dataset.train),\n",
    "    eval_dataset=DatasetAdapterForTransformers(dataset.valid),\n",
    "    data_collator=partial(collate_fn, preprocessor=reference_preprocessor),\n",
    "    compute_metrics=compute_coco_metrics,\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")\n",
    "\n",
    "evaluator = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        per_device_eval_batch_size=BATCH_SIZE[2],\n",
    "        dataloader_drop_last=False,\n",
    "        do_train=False,\n",
    "        do_eval=True,\n",
    "    ),\n",
    "    train_dataset=DatasetAdapterForTransformers(dataset.train),\n",
    "    eval_dataset=DatasetAdapterForTransformers(dataset.valid),\n",
    "    data_collator=partial(collate_fn, preprocessor=reference_preprocessor),\n",
    "    compute_metrics=compute_coco_metrics\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T08:01:20.525140Z",
     "start_time": "2025-06-25T08:01:19.771140Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer.train(resume_from_checkpoint=True)\n",
    "#trainer.train()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['class_embed.0.weight', 'class_embed.0.bias', 'class_embed.1.weight', 'class_embed.1.bias', 'class_embed.2.weight', 'class_embed.2.bias', 'class_embed.3.weight', 'class_embed.3.bias', 'class_embed.4.weight', 'class_embed.4.bias', 'class_embed.5.weight', 'class_embed.5.bias', 'bbox_embed.0.layers.0.weight', 'bbox_embed.0.layers.0.bias', 'bbox_embed.0.layers.1.weight', 'bbox_embed.0.layers.1.bias', 'bbox_embed.0.layers.2.weight', 'bbox_embed.0.layers.2.bias', 'bbox_embed.1.layers.0.weight', 'bbox_embed.1.layers.0.bias', 'bbox_embed.1.layers.1.weight', 'bbox_embed.1.layers.1.bias', 'bbox_embed.1.layers.2.weight', 'bbox_embed.1.layers.2.bias', 'bbox_embed.2.layers.0.weight', 'bbox_embed.2.layers.0.bias', 'bbox_embed.2.layers.1.weight', 'bbox_embed.2.layers.1.bias', 'bbox_embed.2.layers.2.weight', 'bbox_embed.2.layers.2.bias', 'bbox_embed.3.layers.0.weight', 'bbox_embed.3.layers.0.bias', 'bbox_embed.3.layers.1.weight', 'bbox_embed.3.layers.1.bias', 'bbox_embed.3.layers.2.weight', 'bbox_embed.3.layers.2.bias', 'bbox_embed.4.layers.0.weight', 'bbox_embed.4.layers.0.bias', 'bbox_embed.4.layers.1.weight', 'bbox_embed.4.layers.1.bias', 'bbox_embed.4.layers.2.weight', 'bbox_embed.4.layers.2.bias', 'bbox_embed.5.layers.0.weight', 'bbox_embed.5.layers.0.bias', 'bbox_embed.5.layers.1.weight', 'bbox_embed.5.layers.1.bias', 'bbox_embed.5.layers.2.weight', 'bbox_embed.5.layers.2.bias'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20800' max='16250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20800/16250 : < :, Epoch 32/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20800, training_loss=0.0, metrics={'train_runtime': 0.0039, 'train_samples_per_second': 133945715.163, 'train_steps_per_second': 4185803.599, 'total_flos': 2.099592177010606e+20, 'train_loss': 0.0, 'epoch': 32.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-06-26T02:13:36.544714Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.evaluate()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 80/140 01:21 < 01:01, 0.97 it/s]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "archived[0]",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(archived[0])",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "archived[1]",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(archived[1])",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "archived[1][1]",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
