{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TTA Example"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports and Configs"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "from os import path, environ\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "from torchinfo import summary\n",
    "\n",
    "from ttadapters import datasets, models, methods\n",
    "from ttadapters.utils import visualizer, validator\n",
    "from ttadapters.datasets import DatasetHolder, scenarios"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "environ[\"TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS\"] = \"1\"\n",
    "environ[\"TORCHDYNAMO_CAPTURE_DYNAMIC_OUTPUT_SHAPE_OPS\"] = \"1\"\n",
    "\n",
    "torch._dynamo.config.capture_scalar_outputs = True\n",
    "torch._dynamo.config.suppress_errors = True"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Parse Arguments"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set Batch Size\n",
    "BATCH_SIZE = 2, 8, 1  # Local\n",
    "#BATCH_SIZE = 40, 200, 1  # A100 or H100\n",
    "ACCUMULATE_STEPS = 1\n",
    "\n",
    "# Set Data Root\n",
    "DATA_ROOT = path.join(\".\", \"data\")\n",
    "\n",
    "# Set Target Dataset\n",
    "SOURCE_DOMAIN = datasets.SHIFTDataset\n",
    "\n",
    "# Set Model List\n",
    "MODEL_ZOO = [\"rcnn\", \"swinrcnn\", \"yolo11\", \"rtdetr\"]\n",
    "MODEL_TYPE = MODEL_ZOO[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create argument parser\n",
    "parser = ArgumentParser(description=\"Adaptation experiment script for Test-Time Adapters\")\n",
    "\n",
    "# Add model arguments\n",
    "parser.add_argument(\"--dataset\", type=str, choices=[\"shift\", \"city\"], default=\"shift\", help=\"Training dataset\")\n",
    "parser.add_argument(\"--model\", type=str, choices=MODEL_ZOO, default=MODEL_TYPE, help=\"Model architecture\")\n",
    "\n",
    "# Add training arguments\n",
    "parser.add_argument(\"--train-batch\", type=int, default=BATCH_SIZE[0], help=\"Training batch size\")\n",
    "parser.add_argument(\"--valid-batch\", type=int, default=BATCH_SIZE[1], help=\"Validation batch size\")\n",
    "parser.add_argument(\"--accum-step\", type=int, default=ACCUMULATE_STEPS, help=\"Gradient accumulation steps\")\n",
    "parser.add_argument(\"--data-root\", type=str, default=DATA_ROOT, help=\"Root directory for datasets\")\n",
    "parser.add_argument(\"--device\", type=int, default=0, help=\"CUDA device number\")\n",
    "parser.add_argument(\"--additional_gpu\", type=int, default=0, help=\"Additional CUDA device count\")\n",
    "parser.add_argument(\"--use-bf16\", action=\"store_true\", help=\"Use bfloat16 precision\")\n",
    "\n",
    "# Parsing arguments\n",
    "if \"ipykernel\" in sys.modules:\n",
    "    args = parser.parse_args([])\n",
    "    print(\"INFO: Running in notebook mode with default arguments\")\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "\n",
    "# Update global variables based on parsed arguments\n",
    "BATCH_SIZE = args.train_batch, args.valid_batch, BATCH_SIZE[2]\n",
    "ACCUMULATE_STEPS = args.accum_step\n",
    "DATA_ROOT = args.data_root\n",
    "MODEL_TYPE = args.model\n",
    "match args.dataset:\n",
    "    case \"shift\":\n",
    "        SOURCE_DOMAIN = datasets.SHIFTDataset\n",
    "    case \"city\":\n",
    "        SOURCE_DOMAIN = datasets.CityScapesDataset\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported dataset: {args.dataset}\")\n",
    "print(f\"INFO: Set batch size - Train: {BATCH_SIZE[0]}, Valid: {BATCH_SIZE[1]}, Test: {BATCH_SIZE[2]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Check GPU Availability"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!nvidia-smi",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set CUDA Device Number\n",
    "DEVICE_NUM = 0 if not args.device else args.device\n",
    "ADDITIONAL_GPU = 0 if not args.additional_gpu else args.additional_gpu\n",
    "DATA_TYPE = torch.float32 if not args.use_bf16 else torch.bfloat16\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if ADDITIONAL_GPU:\n",
    "        torch.cuda.set_device(DEVICE_NUM)\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{DEVICE_NUM}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DEVICE_NUM = -1\n",
    "\n",
    "print(f\"INFO: Using device - {device}\" + (f\":{DEVICE_NUM}\" if ADDITIONAL_GPU else \"\"))\n",
    "print(f\"INFO: Using data precision - {DATA_TYPE}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define Dataset"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fast download patch\n",
    "datasets.patch_fast_download_for_object_detection()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dataset info\n",
    "CLASSES = datasets.SHIFTClearDatasetForObjectDetection.classes\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "print(f\"INFO: Number of classes - {NUM_CLASSES} {CLASSES}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Base Model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize base_model\n",
    "match MODEL_TYPE:\n",
    "    case \"rcnn\":\n",
    "        base_model = models.FasterRCNNForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = base_model.load_from(**vars(base_model.Weights.SHIFT_CLEAR_NATUREYOO if SOURCE_DOMAIN == datasets.SHIFTDataset else base_model.Weights.CITYSCAPES), strict=False)\n",
    "    case \"swinrcnn\":\n",
    "        base_model = models.SwinRCNNForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = base_model.load_from(**vars(base_model.Weights.SHIFT_CLEAR_NATUREYOO if SOURCE_DOMAIN == datasets.SHIFTDataset else base_model.Weights.CITYSCAPES), strict=False)\n",
    "    case \"yolo11\":\n",
    "        DATA_TYPE = torch.bfloat16  # bf16 default\n",
    "        base_model = models.YOLO11ForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = base_model.load_from(**vars(base_model.Weights.SHIFT_CLEAR if SOURCE_DOMAIN == datasets.SHIFTDataset else base_model.Weights.CITYSCAPES), strict=False)\n",
    "    case \"rtdetr\":\n",
    "        DATA_TYPE = torch.bfloat16  # bf16 default\n",
    "        base_model = models.RTDetrForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = base_model.load_from(**vars(base_model.Weights.SHIFT_CLEAR if SOURCE_DOMAIN == datasets.SHIFTDataset else base_model.Weights.CITYSCAPES), strict=False)\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported model type: {MODEL_TYPE}\")\n",
    "\n",
    "print(\"INFO: Model state loaded -\", load_result)\n",
    "base_model.to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "summary(base_model)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load Adaptation Method"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Method configuration\n",
    "adaptive_config = methods.APTConfig(\n",
    "    # Optimization\n",
    "    optim=\"SGD\",\n",
    "    momentum=0,\n",
    "    adapt_lr=1e-5,\n",
    "    backbone_lr=1e-5,\n",
    "    head_lr=1e-5,\n",
    "\n",
    "    # Tracking\n",
    "    max_age=3,\n",
    "    min_hits=1,\n",
    "    iou_threshold=0.8,\n",
    "\n",
    "    # Loss\n",
    "    loss_type=\"smooth_l1\",\n",
    "    loss_weight=1.0,\n",
    "    use_confidence_weighting=True,\n",
    "    conf_threshold=0.7,\n",
    "    min_confidence_for_update=0.3,\n",
    "\n",
    "    # Update strategy\n",
    "    update_backbone=False,\n",
    "    update_head=False,\n",
    "    update_bn=True,\n",
    "    update_fpn_last_layer=False,\n",
    "    update_box_regressor_last_layer=False,\n",
    "\n",
    "    # Memory & Stabilization\n",
    "    buffer_size=500,\n",
    "    loss_ema_decay=0.9\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize method\n",
    "adaptive_model = methods.APTEngine(base_model, adaptive_config)\n",
    "adaptive_model.to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Evaluation"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load Pretrained APT Weights & Un-Freeze Model Encoder\n",
    "# Allow FPN/Encoder to adapt during online adaptation\n",
    "base_model.eval()\n",
    "adaptive_model.online()\n",
    "summary(adaptive_model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Scenarios"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensure split (required due to Scenario class works with coroutines)\n",
    "_ = datasets.SHIFTContinuousSubsetForObjectDetection(root=DATA_ROOT, train=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_preparation = base_model.DataPreparation(datasets.base.BaseDataset(), evaluation_mode=True)\n",
    "\n",
    "match SOURCE_DOMAIN:\n",
    "    case datasets.SHIFTDataset:\n",
    "        discrete_scenario = scenarios.SHIFTDiscreteScenario(\n",
    "            root=DATA_ROOT, valid=True, order=scenarios.SHIFTDiscreteScenario.WHWPAPER, transforms=data_preparation.transforms\n",
    "        )\n",
    "    case datasets.CityScapesDataset:\n",
    "        discrete_scenario = None\n",
    "        continuous_scenario = None\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported dataset: {SOURCE_DOMAIN}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "methods = {\n",
    "    #'Direct-Test': base_model,\n",
    "    adaptive_model.model_name: adaptive_model\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "evaluator = validator.DetectionEvaluator(list(methods.values()), classes=CLASSES, data_preparation=data_preparation, dtype=DATA_TYPE, device=device, no_grad=False)\n",
    "evaluator_loader_params = dict(batch_size=BATCH_SIZE[2], shuffle=False, collate_fn=data_preparation.collate_fn)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualizer.visualize_metrics(discrete_scenario(**evaluator_loader_params).play(evaluator, index=methods.keys()))",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttadapters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
