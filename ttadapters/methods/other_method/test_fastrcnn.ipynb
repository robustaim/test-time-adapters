{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RT-DETR Pretraining with SHIFT-Discrete Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 22 07:00:32 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   78C    P0             247W / 250W |   7930MiB / 16384MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE-16GB           Off | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   77C    P0             247W / 250W |  10064MiB / 16384MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-PCIE-16GB           Off | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   79C    P0             206W / 250W |   5596MiB / 16384MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla P100-PCIE-16GB           Off | 00000000:08:00.0 Off |                    0 |\n",
      "| N/A   78C    P0             246W / 250W |   9960MiB / 16384MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla P100-PCIE-16GB           Off | 00000000:0C:00.0 Off |                    0 |\n",
      "| N/A   78C    P0             237W / 250W |   7108MiB / 16384MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla P100-PCIE-16GB           Off | 00000000:0D:00.0 Off |                    0 |\n",
      "| N/A   79C    P0             219W / 250W |   9094MiB / 16384MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla P100-PCIE-16GB           Off | 00000000:0E:00.0 Off |                    0 |\n",
      "| N/A   79C    P0             228W / 250W |   5594MiB / 16384MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla P100-PCIE-16GB           Off | 00000000:0F:00.0 Off |                    0 |\n",
      "| N/A   78C    P0             248W / 250W |   6504MiB / 16384MiB |    100%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA Device Number\n",
    "DEVICE_NUM = 6\n",
    "\n",
    "from os import environ\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = str(DEVICE_NUM)\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/workspace/ptta\") # os.chdir(\"/home/ubuntu/test-time-adapters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ttadapters.datasets import BaseDataset, DatasetHolder, DataLoaderHolder\n",
    "from ttadapters.datasets import (\n",
    "    SHIFTDataset,\n",
    "    SHIFTClearDatasetForObjectDetection,\n",
    "    SHIFTCorruptedDatasetForObjectDetection,\n",
    "    SHIFTDiscreteSubsetForObjectDetection\n",
    ")\n",
    "from ttadapters import datasets\n",
    "\n",
    "from ttadapters.models.rcnn import FasterRCNNForObjectDetection, SwinRCNNForObjectDetection\n",
    "\n",
    "from supervision.metrics.mean_average_precision import MeanAveragePrecision\n",
    "from supervision.detection.core import Detections\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from detectron2.layers import FrozenBatchNorm2d\n",
    "from detectron2.utils.events import EventStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ttadapters.methods.other_method import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from detectron2.structures import Instances\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"INFO: Using device - {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME = \"detectron_test\"\n",
    "RUN_NAME = \"Faster-RCNN_R50\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = path.join(\".\", \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.structures import ImageList\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "    return dict(\n",
    "        pixel_values=ImageList.from_tensors(images, size_divisibility=32),\n",
    "        labels=[dict(\n",
    "            class_labels=item['boxes2d_classes'].long(),\n",
    "            boxes=item[\"boxes2d\"].float()\n",
    "        ) for item in targets]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.structures import Boxes, Instances\n",
    "from torchvision.tv_tensors import Image, BoundingBoxes\n",
    "\n",
    "def collate_fn(batch: list[Image, BoundingBoxes]):\n",
    "    batched_inputs = []\n",
    "    for image, metadata in batch:\n",
    "        original_height, original_width = image.shape[-2:]\n",
    "        instances = Instances(image_size=(original_height, original_width))\n",
    "        instances.gt_boxes = Boxes(metadata[\"boxes2d\"])  # xyxy\n",
    "        instances.gt_classes = metadata[\"boxes2d_classes\"]\n",
    "        batched_inputs.append({\n",
    "            \"image\": image,\n",
    "            \"instances\": instances,\n",
    "            \"height\": original_height,\n",
    "            \"width\": original_width\n",
    "        })\n",
    "    return batched_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SWIN_T_BACKBONE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SWIN_T_BACKBONE:\n",
    "    model = SwinRCNNForObjectDetection(dataset=SHIFTDataset)\n",
    "else:\n",
    "    model = FasterRCNNForObjectDetection(dataset=SHIFTDataset)\n",
    "\n",
    "model.load_from(model.Weights.NATUREYOO, weight_key=\"model\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_to_subset_types(task: str):\n",
    "    T = SHIFTDiscreteSubsetForObjectDetection.SubsetType\n",
    "\n",
    "    # weather\n",
    "    if task == \"cloudy\":\n",
    "        return T.CLOUDY_DAYTIME\n",
    "    if task == \"overcast\":\n",
    "        return T.OVERCAST_DAYTIME\n",
    "    if task == \"rainy\":\n",
    "        return T.RAINY_DAYTIME\n",
    "    if task == \"foggy\":\n",
    "        return T.FOGGY_DAYTIME\n",
    "\n",
    "    # time\n",
    "    if task == \"night\":\n",
    "        return T.CLEAR_NIGHT\n",
    "    if task in {\"dawn\", \"dawn/dusk\"}:\n",
    "        return T.CLEAR_DAWN\n",
    "    if task == \"clear\":\n",
    "        return T.CLEAR_DAYTIME\n",
    "    \n",
    "    # simple\n",
    "    if task == \"normal\":\n",
    "        return T.NORMAL\n",
    "    if task == \"corrupted\":\n",
    "        return T.CORRUPTED\n",
    "\n",
    "    raise ValueError(f\"Unknown task: {task}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "class SHIFTCorruptedDatasetForObjectDetection(SHIFTDiscreteSubsetForObjectDetection):\n",
    "    def __init__(\n",
    "            self, root: str, force_download: bool = False,\n",
    "            train: bool = True, valid: bool = False,\n",
    "            transform= None, target_transform = None, transforms = None,\n",
    "            task = \"clear\"\n",
    "    ):\n",
    "        super().__init__(\n",
    "            root=root, force_download=force_download,\n",
    "            train=train, valid=valid, subset_type=task_to_subset_types(task),\n",
    "            transform=transform, target_transform=target_transform, transforms=transforms\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "\n",
    "def evaluate_for(self, loader, loader_length, threshold=0.0, dtype=torch.float32, device=torch.device(\"cuda\")):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    self.eval()\n",
    "\n",
    "    map_metric = MeanAveragePrecision()\n",
    "    predictions_list = []\n",
    "    targets_list = []\n",
    "    collapse_time = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(loader, total=loader_length, desc=\"Evaluation\"):\n",
    "            with torch.autocast(device_type=device.type, dtype=dtype):\n",
    "                start = time.time()\n",
    "                outputs = self(batch)\n",
    "                collapse_time += time.time() - start\n",
    "\n",
    "            for i, (output, input_data) in enumerate(zip(outputs, batch)):\n",
    "                instances = output['instances']\n",
    "                mask = instances.scores > threshold\n",
    "\n",
    "                pred_detection = Detections(\n",
    "                    xyxy=instances.pred_boxes.tensor[mask].detach().cpu().numpy(),\n",
    "                    class_id=instances.pred_classes[mask].detach().cpu().numpy(),\n",
    "                    confidence=instances.scores[mask].detach().cpu().numpy()\n",
    "                )\n",
    "                gt_instances = input_data['instances']\n",
    "                target_detection = Detections(\n",
    "                    xyxy=gt_instances.gt_boxes.tensor.detach().cpu().numpy(),\n",
    "                    class_id=gt_instances.gt_classes.detach().cpu().numpy()\n",
    "                )\n",
    "\n",
    "                predictions_list.append(pred_detection)\n",
    "                targets_list.append(target_detection)\n",
    "\n",
    "        map_metric.update(predictions=predictions_list, targets=targets_list)\n",
    "        m_ap = map_metric.compute()\n",
    "\n",
    "        per_class_map = {\n",
    "            f\"{CLASSES[idx]}_mAP@0.50:0.95\": m_ap.ap_per_class[idx].mean().item()\n",
    "            for idx in m_ap.matched_classes\n",
    "        }\n",
    "        performances = {\n",
    "            \"collapse_time\": collapse_time,\n",
    "            \"fps\": loader_length / collapse_time\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            \"mAP@0.50:0.95\": m_ap.map50_95.item(),\n",
    "            \"mAP@0.50\": m_ap.map50.item(),\n",
    "            \"mAP@0.75\": m_ap.map75.item(),\n",
    "            **per_class_map,\n",
    "            **performances\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct_method\n",
    "for task in [\"cloudy\", \"overcast\", \"foggy\", \"rainy\", \"dawn\", \"night\", \"clear\"]:\n",
    "    dataset=SHIFTCorruptedDatasetForObjectDetection(\n",
    "        root=DATA_ROOT, valid=True,\n",
    "        transform=datasets.detectron_image_transform,\n",
    "        transforms=datasets.default_valid_transforms,\n",
    "        task=task\n",
    "    )\n",
    "    print(f\"start {task}\")\n",
    "    CLASSES = dataset\n",
    "    NUM_CLASSES = len(CLASSES)\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "    dataloader.valid_len = math.ceil(len(dataset)/4)\n",
    "    result = evaluate_for(model, dataloader, dataloader.valid_len)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ActMAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_activation_alignment(model, method, data_root, batch_size=16):\n",
    "    dataset = SHIFTClearDatasetForObjectDetection(\n",
    "        root=data_root, train=True,\n",
    "        transform=datasets.detectron_image_transform,\n",
    "        transforms=datasets.default_valid_transforms\n",
    "    )\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    loader.train_len = math.ceil(len(dataset)/batch_size)\n",
    "\n",
    "    # model unfreeze\n",
    "    for k, v in model.named_parameters():\n",
    "        v.requires_grad = True\n",
    "\n",
    "    chosen_bn_info = []\n",
    "    if method == \"actmad\": \n",
    "        for name, m in model.named_modules():\n",
    "            if isinstance(m, (FrozenBatchNorm2d)):\n",
    "                chosen_bn_info.append((name, m))\n",
    "\n",
    "    # chosen_bn_layers\n",
    "    \"\"\"\n",
    "    Since high-level representations are more sensitive to domain shift,\n",
    "    only the later BN layers are selected. \n",
    "    The cutoff point is determined empirically.\n",
    "    \"\"\"\n",
    "    cutoff = len(chosen_bn_info) // 2\n",
    "    chosen_bn_info = chosen_bn_info[cutoff:]\n",
    "    chosen_bn_layers = [module for name, module in chosen_bn_info]\n",
    "    layer_names = [name for name, module in chosen_bn_info]\n",
    "\n",
    "    n_chosen_layers = len(chosen_bn_layers)\n",
    "\n",
    "    save_outputs = [utils.SaveOutput() for _ in range(n_chosen_layers)]\n",
    "\n",
    "    clean_mean_act_list = [utils.AverageMeter() for _ in range(n_chosen_layers)]\n",
    "    clean_var_act_list = [utils.AverageMeter() for _ in range(n_chosen_layers)]\n",
    "\n",
    "    clean_mean_list_final = []\n",
    "    clean_var_list_final = []\n",
    "    \n",
    "    # extract the activation alignment in train dataset\n",
    "    print(\"Start extracting BN statistics from the training dataset\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, total=loader.train_len, desc=\"Evaluation\"):\n",
    "            model.eval()\n",
    "            hook_list = [chosen_bn_layers[i].register_forward_hook(save_outputs[i]) for i in range(n_chosen_layers)]\n",
    "            _ = model(batch)\n",
    "\n",
    "            for i in range(n_chosen_layers):\n",
    "                clean_mean_act_list[i].update(save_outputs[i].get_out_mean())  # compute mean from clean data\n",
    "                clean_var_act_list[i].update(save_outputs[i].get_out_var())  # compute variane from clean data\n",
    "\n",
    "                save_outputs[i].clear()\n",
    "                hook_list[i].remove()\n",
    "\n",
    "        for i in range(n_chosen_layers):\n",
    "            clean_mean_list_final.append(clean_mean_act_list[i].avg)  # [C, H, W]\n",
    "            clean_var_list_final.append(clean_var_act_list[i].avg)  # [C, H, W]\n",
    "\n",
    "        return clean_mean_list_final, clean_var_list_final, layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actmad | extract clear data bn\n",
    "\n",
    "# hyperparameter \n",
    "CLEAN_BN_EXTRACT_BATCH = 8\n",
    "stats_save_path = Path(\"/workspace/ptta/ttadapters/methods/other_method\") / f\"actmad_clean_statistics_faster_rcnn.pt\"\n",
    "\n",
    "statistics = {}\n",
    "\n",
    "# 저장된 statistics가 있는지 확인\n",
    "if stats_save_path.exists():\n",
    "    print(f\"Loading saved ActMAD statistics from {stats_save_path}\")\n",
    "    saved_stats = torch.load(stats_save_path)\n",
    "    statistics[\"clean_mean_list_final\"] = saved_stats[\"clean_mean_list_final\"]\n",
    "    statistics[\"clean_var_list_final\"] = saved_stats[\"clean_var_list_final\"]\n",
    "    statistics[\"layer_names\"] = saved_stats[\"layer_names\"]\n",
    "else:\n",
    "    print(\"Extracting ActMAD statistics from clean data...\")\n",
    "    (\n",
    "        statistics[\"clean_mean_list_final\"],\n",
    "        statistics[\"clean_var_list_final\"],\n",
    "        statistics[\"layer_names\"]\n",
    "    ) = extract_activation_alignment(\n",
    "        model=model, method=\"actmad\",\n",
    "        data_root=DATA_ROOT, \n",
    "        batch_size=CLEAN_BN_EXTRACT_BATCH\n",
    "        )\n",
    "\n",
    "    # Statistics만 저장 (chosen_bn_layers는 저장하지 않음)\n",
    "    print(f\"Saving ActMAD statistics to {stats_save_path}\")\n",
    "    torch.save({\n",
    "        \"clean_mean_list_final\": statistics[\"clean_mean_list_final\"],\n",
    "        \"clean_var_list_final\": statistics[\"clean_var_list_final\"],\n",
    "        \"layer_names\": statistics[\"layer_names\"]\n",
    "    }, stats_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_mean_list_final = statistics[\"clean_mean_list_final\"]\n",
    "clean_var_list_final = statistics[\"clean_var_list_final\"]\n",
    "layer_names = statistics[\"layer_names\"]\n",
    "\n",
    "current_bn_dict = {name: module for name, module in model.named_modules()\n",
    "                    if isinstance(module, FrozenBatchNorm2d)}\n",
    "\n",
    "chosen_bn_layers = []\n",
    "for layer_name in layer_names:\n",
    "    if layer_name in current_bn_dict:\n",
    "        chosen_bn_layers.append(current_bn_dict[layer_name])\n",
    "    else:\n",
    "        print(f\"Warning: Layer {layer_name} not found!\")\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "                model.parameters(),\n",
    "                lr=0.001,  \n",
    "            )\n",
    "# Unfreeze model parameters for ActMAD\n",
    "for k, v in model.named_parameters():\n",
    "    v.requires_grad = True\n",
    "\n",
    "for task in [\"cloudy\", \"overcast\", \"foggy\", \"rainy\", \"dawn\", \"night\", \"clear\"]:\n",
    "    map_metric = MeanAveragePrecision()\n",
    "    predictions_list = []\n",
    "    targets_list = []\n",
    "    threshold = 0.0\n",
    "\n",
    "    # data load\n",
    "    dataset=SHIFTCorruptedDatasetForObjectDetection(\n",
    "        root=DATA_ROOT, valid=True,\n",
    "        transform=datasets.detectron_image_transform,\n",
    "        transforms=datasets.default_valid_transforms,\n",
    "        task=task\n",
    "    )\n",
    "    print(f\"start {task}\")\n",
    "    CLASSES = dataset\n",
    "    NUM_CLASSES = len(CLASSES)\n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "    dataloader.valid_len = math.ceil(len(dataset)/4)\n",
    "\n",
    "    # Unfreeze model parameters for ActMAD\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    n_chosen_layers = len(chosen_bn_layers)\n",
    "\n",
    "    l1_loss = nn.L1Loss(reduction=\"mean\")\n",
    "\n",
    "    for batch in tqdm(dataloader, total=dataloader.valid_len, desc=\"Evaluation\"):\n",
    "        model.eval()\n",
    "        # for m in model.modules():\n",
    "        #     if isinstance(m, (FrozenBatchNorm2d)):\n",
    "        #         m.eval()\n",
    "        optimizer.zero_grad()\n",
    "        save_outputs_tta = [utils.SaveOutput() for _ in range(n_chosen_layers)]\n",
    "\n",
    "        hook_list_tta = [chosen_bn_layers[x].register_forward_hook(save_outputs_tta[x])\n",
    "                        for x in range(n_chosen_layers)]\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(batch)\n",
    "\n",
    "        # Extract current batch statistics\n",
    "        batch_mean_tta = [save_outputs_tta[x].get_out_mean() for x in range(n_chosen_layers)]\n",
    "        batch_var_tta = [save_outputs_tta[x].get_out_var() for x in range(n_chosen_layers)]\n",
    "\n",
    "        # Compute ActMAD loss\n",
    "        loss_mean = torch.tensor(0, requires_grad=True, dtype=torch.float).float().to(device)\n",
    "        loss_var = torch.tensor(0, requires_grad=True, dtype=torch.float).float().to(device)\n",
    "\n",
    "        for i in range(n_chosen_layers):\n",
    "            loss_mean += l1_loss(batch_mean_tta[i].to(device), clean_mean_list_final[i].to(device))\n",
    "            loss_var += l1_loss(batch_var_tta[i].to(device), clean_var_list_final[i].to(device))\n",
    "            \n",
    "        loss =  loss_mean +  loss_var\n",
    "\n",
    "        # Backward and update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Clean up hooks \n",
    "        for z in range(n_chosen_layers):\n",
    "            save_outputs_tta[z].clear()\n",
    "            hook_list_tta[z].remove()\n",
    "        \n",
    "        for i, (output, input_data) in enumerate(zip(outputs, batch)):\n",
    "                instances = output['instances']\n",
    "                mask = instances.scores > threshold\n",
    "\n",
    "                pred_detection = Detections(\n",
    "                    xyxy=instances.pred_boxes.tensor[mask].detach().cpu().numpy(),\n",
    "                    class_id=instances.pred_classes[mask].detach().cpu().numpy(),\n",
    "                    confidence=instances.scores[mask].detach().cpu().numpy()\n",
    "                )\n",
    "                gt_instances = input_data['instances']\n",
    "                target_detection = Detections(\n",
    "                    xyxy=gt_instances.gt_boxes.tensor.detach().cpu().numpy(),\n",
    "                    class_id=gt_instances.gt_classes.detach().cpu().numpy()\n",
    "                )\n",
    "\n",
    "                predictions_list.append(pred_detection)\n",
    "                targets_list.append(target_detection)\n",
    "\n",
    "    map_metric.update(predictions=predictions_list, targets=targets_list)\n",
    "    print(f\"start {task} mAP computation\")\n",
    "    m_ap = map_metric.compute()\n",
    "\n",
    "    per_class_map = {\n",
    "        f\"{CLASSES[idx]}_mAP@0.50:0.95\": m_ap.ap_per_class[idx].mean().item()\n",
    "        for idx in m_ap.matched_classes\n",
    "    }\n",
    "\n",
    "    print({\n",
    "        \"mAP@0.50:0.95\": m_ap.map50_95.item(),\n",
    "        \"mAP@0.50\": m_ap.map50.item(),\n",
    "        \"mAP@0.75\": m_ap.map75.item(),\n",
    "        **per_class_map,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_norm_adaptation(model, source_sum=128):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.BatchNorm2d, FrozenBatchNorm2d)):\n",
    "            module.adapt_type = \"NORM\"\n",
    "            module.source_sum = source_sum\n",
    "\n",
    "            # ContinualTTA NORM forward method 추가\n",
    "            def norm_forward(self, x):\n",
    "                if hasattr(self, 'adapt_type') and self.adapt_type == \"NORM\":\n",
    "                    # NORM adaptation logic from ContinualTTA\n",
    "                    alpha = x.shape[0] / (self.source_sum + x.shape[0])\n",
    "                    running_mean = (1 - alpha) * self.running_mean + alpha * x.mean(dim=[0,2,3])\n",
    "                    running_var = (1 - alpha) * self.running_var + alpha * x.var(dim=[0,2,3])\n",
    "                    scale = self.weight * (running_var + self.eps).rsqrt()\n",
    "                    bias = self.bias - running_mean * scale\n",
    "                else:\n",
    "                    # Original forward\n",
    "                    scale = self.weight * (self.running_var + self.eps).rsqrt()\n",
    "                    bias = self.bias - self.running_mean * scale\n",
    "\n",
    "                scale = scale.reshape(1, -1, 1, 1)\n",
    "                bias = bias.reshape(1, -1, 1, 1)\n",
    "                out_dtype = x.dtype\n",
    "                out = x * scale.to(out_dtype) + bias.to(out_dtype)\n",
    "                return out\n",
    "\n",
    "            # Replace forward method\n",
    "            module.forward = norm_forward.__get__(module, module.__class__)\n",
    "            print(f\"Applied NORM adaptation to {name}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = apply_norm_adaptation(model, source_sum=128)\n",
    "\n",
    "for task in [\"cloudy\", \"overcast\", \"foggy\", \"rainy\", \"dawn\", \"night\", \"clear\"]:\n",
    "    map_metric = MeanAveragePrecision()\n",
    "    predictions_list = []\n",
    "    targets_list = []\n",
    "    threshold = 0.0\n",
    "\n",
    "    # data load\n",
    "    dataset=SHIFTCorruptedDatasetForObjectDetection(\n",
    "        root=DATA_ROOT, valid=True,\n",
    "        transform=datasets.detectron_image_transform,\n",
    "        transforms=datasets.default_valid_transforms,\n",
    "        task=task\n",
    "    )\n",
    "    print(f\"start {task}\")\n",
    "    CLASSES = dataset\n",
    "    NUM_CLASSES = len(CLASSES)\n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "    dataloader.valid_len = math.ceil(len(dataset)/4)\n",
    "\n",
    "    for batch in tqdm(dataloader, total=dataloader.valid_len, desc=\"Evaluation\"):\n",
    "        model.eval()\n",
    "        outputs = model(batch)\n",
    "     \n",
    "        for i, (output, input_data) in enumerate(zip(outputs, batch)):\n",
    "                instances = output['instances']\n",
    "                mask = instances.scores > threshold\n",
    "\n",
    "                pred_detection = Detections(\n",
    "                    xyxy=instances.pred_boxes.tensor[mask].detach().cpu().numpy(),\n",
    "                    class_id=instances.pred_classes[mask].detach().cpu().numpy(),\n",
    "                    confidence=instances.scores[mask].detach().cpu().numpy()\n",
    "                )\n",
    "                gt_instances = input_data['instances']\n",
    "                target_detection = Detections(\n",
    "                    xyxy=gt_instances.gt_boxes.tensor.detach().cpu().numpy(),\n",
    "                    class_id=gt_instances.gt_classes.detach().cpu().numpy()\n",
    "                )\n",
    "\n",
    "                predictions_list.append(pred_detection)\n",
    "                targets_list.append(target_detection)\n",
    "\n",
    "    map_metric.update(predictions=predictions_list, targets=targets_list)\n",
    "    print(f\"start {task} mAP computation\")\n",
    "    m_ap = map_metric.compute()\n",
    "\n",
    "    per_class_map = {\n",
    "        f\"{CLASSES[idx]}_mAP@0.50:0.95\": m_ap.ap_per_class[idx].mean().item()\n",
    "        for idx in m_ap.matched_classes\n",
    "    }\n",
    "\n",
    "    print({\n",
    "        \"mAP@0.50:0.95\": m_ap.map50_95.item(),\n",
    "        \"mAP@0.50\": m_ap.map50.item(),\n",
    "        \"mAP@0.75\": m_ap.map75.item(),\n",
    "        **per_class_map,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dua_adaptation(model, decay_factor=0.94, mom_pre=0.01, min_momentum_constant=0.0001):\n",
    "    for name, module in model.named_modules():\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, (nn.BatchNorm2d, FrozenBatchNorm2d)):\n",
    "                module.adapt_type = \"DUA\"\n",
    "                module.min_momentum_constant = min_momentum_constant\n",
    "                module.decay_factor = decay_factor\n",
    "                module.mom_pre = mom_pre\n",
    "\n",
    "            if not hasattr(module, 'original_running_mean'):\n",
    "                module.original_running_mean = module.running_mean.clone()\n",
    "                module.original_running_var = module.running_var.clone()\n",
    "\n",
    "            def dua_forward(self, x):\n",
    "                if hasattr(self, 'adapt_type') and self.adapt_type == \"DUA\":\n",
    "                    with torch.no_grad():\n",
    "                        current_momentum = self.mom_pre + self.min_momentum_constant\n",
    "                        batch_mean = x.mean(dim=[0, 2, 3])\n",
    "                        batch_var = x.var(dim=[0, 2, 3],unbiased=True)\n",
    "\n",
    "                        # running statistics 업데이트 (gradient 없이)\n",
    "                        self.running_mean.mul_(1 - current_momentum).add_(batch_mean, alpha=current_momentum)\n",
    "                        self.running_var.mul_(1 - current_momentum).add_(batch_var, alpha=current_momentum)\n",
    "                        self.mom_pre *= self.decay_factor\n",
    "                        self.mom_pre *= self.decay_factor\n",
    "                    scale = self.weight * (self.running_var + self.eps).rsqrt()\n",
    "                    bias = self.bias - self.running_mean * scale\n",
    "                else:\n",
    "                    scale = self.weight * (self.running_var + self.eps).rsqrt()\n",
    "                    bias = self.bias - self.running_mean * scale\n",
    "\n",
    "                scale = scale.reshape(1, -1, 1, 1)\n",
    "                bias = bias.reshape(1, -1, 1, 1)\n",
    "                out_dtype = x.dtype\n",
    "                out = x * scale.to(out_dtype) + bias.to(out_dtype)\n",
    "\n",
    "                return out\n",
    "            module.forward = dua_forward.__get__(module, module.__class__)\n",
    "            print(f\"Applied DUA adaptation to {name}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_dua_momentum(model, mom_pre=0.01):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.BatchNorm2d, FrozenBatchNorm2d)) and hasattr(module, 'adapt_type'):\n",
    "            if module.adapt_type == \"DUA\":\n",
    "                module.mom_pre = mom_pre\n",
    "                if hasattr(module, 'original_running_mean'):\n",
    "                    module.running_mean = module.original_running_mean.clone()\n",
    "                    module.running_var = module.original_running_var.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = apply_dua_adaptation(model, decay_factor=0.94, mom_pre=0.0)\n",
    "\n",
    "for task in [\"cloudy\", \"overcast\", \"foggy\", \"rainy\", \"dawn\", \"night\", \"clear\"]:\n",
    "    map_metric = MeanAveragePrecision()\n",
    "    predictions_list = []\n",
    "    targets_list = []\n",
    "    threshold = 0.0\n",
    "\n",
    "    # data load\n",
    "    dataset=SHIFTCorruptedDatasetForObjectDetection(\n",
    "        root=DATA_ROOT, valid=True,\n",
    "        transform=datasets.detectron_image_transform,\n",
    "        transforms=datasets.default_valid_transforms,\n",
    "        task=task\n",
    "    )\n",
    "    print(f\"start {task}\")\n",
    "    CLASSES = dataset\n",
    "    NUM_CLASSES = len(CLASSES)\n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "    dataloader.valid_len = math.ceil(len(dataset)/4)\n",
    "\n",
    "    for batch in tqdm(dataloader, total=dataloader.valid_len, desc=\"Evaluation\"):\n",
    "        model.eval()\n",
    "        outputs = model(batch)\n",
    "     \n",
    "        for i, (output, input_data) in enumerate(zip(outputs, batch)):\n",
    "                instances = output['instances']\n",
    "                mask = instances.scores > threshold\n",
    "\n",
    "                pred_detection = Detections(\n",
    "                    xyxy=instances.pred_boxes.tensor[mask].detach().cpu().numpy(),\n",
    "                    class_id=instances.pred_classes[mask].detach().cpu().numpy(),\n",
    "                    confidence=instances.scores[mask].detach().cpu().numpy()\n",
    "                )\n",
    "                gt_instances = input_data['instances']\n",
    "                target_detection = Detections(\n",
    "                    xyxy=gt_instances.gt_boxes.tensor.detach().cpu().numpy(),\n",
    "                    class_id=gt_instances.gt_classes.detach().cpu().numpy()\n",
    "                )\n",
    "\n",
    "                predictions_list.append(pred_detection)\n",
    "                targets_list.append(target_detection)\n",
    "\n",
    "    map_metric.update(predictions=predictions_list, targets=targets_list)\n",
    "    print(f\"start {task} mAP computation\")\n",
    "    m_ap = map_metric.compute()\n",
    "\n",
    "    per_class_map = {\n",
    "        f\"{CLASSES[idx]}_mAP@0.50:0.95\": m_ap.ap_per_class[idx].mean().item()\n",
    "        for idx in m_ap.matched_classes\n",
    "    }\n",
    "\n",
    "    print({\n",
    "        \"mAP@0.50:0.95\": m_ap.map50_95.item(),\n",
    "        \"mAP@0.50\": m_ap.map50.item(),\n",
    "        \"mAP@0.75\": m_ap.map75.item(),\n",
    "        **per_class_map,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean-Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_mean_teacher_model(model):\n",
    "    \"\"\"\n",
    "    Setup Mean-Teacher model following ContinualTTA pattern\n",
    "    \"\"\"\n",
    "    # Create teacher model as deep copy\n",
    "    teacher_model = copy.deepcopy(model)\n",
    "    teacher_model.eval()\n",
    "    teacher_model.requires_grad_(False)\n",
    "\n",
    "    # Disable online adaptation for teacher\n",
    "    if hasattr(teacher_model, 'online_adapt'):\n",
    "        teacher_model.online_adapt = False\n",
    "\n",
    "    # Setup student model for training\n",
    "    if hasattr(model, 'online_adapt'):\n",
    "        model.online_adapt = False\n",
    "    model.training = True\n",
    "\n",
    "    # Set training mode for specific components\n",
    "    if hasattr(model, 'proposal_generator'):\n",
    "        model.proposal_generator.training = True\n",
    "    if hasattr(model, 'roi_heads'):\n",
    "        model.roi_heads.training = True\n",
    "\n",
    "    return teacher_model\n",
    "\n",
    "def setup_optimizer_for_adaptation(model, lr=1e-4):\n",
    "    \"\"\"\n",
    "    Setup optimizer for normalization layers adaptation\n",
    "    \"\"\"\n",
    "    params = []\n",
    "\n",
    "    # Only adapt normalization layers (following ContinualTTA pattern)\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.BatchNorm2d, nn.LayerNorm)) or 'norm' in name.lower():\n",
    "            if hasattr(module, 'weight') and module.weight is not None:\n",
    "                module.weight.requires_grad_(True)\n",
    "                params.append(module.weight)\n",
    "            if hasattr(module, 'bias') and module.bias is not None:\n",
    "                module.bias.requires_grad_(True)\n",
    "                params.append(module.bias)\n",
    "\n",
    "    if len(params) > 0:\n",
    "        optimizer = torch.optim.SGD(params, lr=lr, momentum=0.9, weight_decay=1e-4)\n",
    "        return optimizer\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def create_strong_augmentation():\n",
    "    \"\"\"\n",
    "    Create strong augmentation for pseudo-labeling\n",
    "    \"\"\"\n",
    "    return T.Compose([\n",
    "        T.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.2),\n",
    "        T.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "    ])\n",
    "\n",
    "def set_pseudo_labels(inputs, outputs, conf_th=0.7):\n",
    "    \"\"\"\n",
    "    Generate pseudo labels from teacher predictions\n",
    "    Following ContinualTTA pattern\n",
    "    \"\"\"\n",
    "    new_inputs = []\n",
    "\n",
    "    for inp, oup in zip(inputs, outputs):\n",
    "        # Get instances with confidence filtering\n",
    "        instances = oup['instances']\n",
    "        mask = instances.scores > conf_th\n",
    "        filtered_instances = instances[mask]\n",
    "\n",
    "        if len(filtered_instances) == 0:\n",
    "            continue\n",
    "\n",
    "        # Create new input for pseudo-labeling\n",
    "        new_inp = {k: inp[k] for k in inp if k not in ['instances']}\n",
    "\n",
    "        # Use the same image for simplicity (in practice, you might want strong augmentation)\n",
    "        new_inp['image'] = inp['image']\n",
    "\n",
    "        # Create pseudo ground truth\n",
    "        pseudo_instances = Instances(inp['instances'].image_size)\n",
    "        pseudo_instances.gt_classes = filtered_instances.pred_classes\n",
    "        pseudo_instances.gt_boxes = filtered_instances.pred_boxes\n",
    "\n",
    "        new_inp['instances'] = pseudo_instances\n",
    "        new_inputs.append(new_inp)\n",
    "\n",
    "    return new_inputs\n",
    "\n",
    "def update_teacher_with_ema(teacher_model, student_model,\n",
    "ema_beta=0.999):\n",
    "    \"\"\"\n",
    "    Update teacher model using Exponential Moving Average\n",
    "    Following ContinualTTA pattern\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        for teacher_param, student_param in zip(teacher_model.parameters(), student_model.parameters()):\n",
    "            if student_param.requires_grad:\n",
    "                teacher_param.data = ema_beta * teacher_param.data + (1 - ema_beta) * student_param.data\n",
    "\n",
    "# Main evaluation code with Mean-Teacher adaptation\n",
    "for task in [\"cloudy\", \"overcast\", \"foggy\", \"rainy\", \"dawn\", \"night\",\n",
    "\"clear\"]:\n",
    "    map_metric = MeanAveragePrecision()\n",
    "    predictions_list = []\n",
    "    targets_list = []\n",
    "    threshold = 0.0\n",
    "\n",
    "    # Mean-Teacher hyperparameters\n",
    "    ema_beta = 0.999\n",
    "    conf_threshold = 0.7\n",
    "    learning_rate = 1e-4\n",
    "\n",
    "    # Data loading\n",
    "    dataset = SHIFTCorruptedDatasetForObjectDetection(\n",
    "        root=DATA_ROOT, valid=True,\n",
    "        transform=datasets.detectron_image_transform,\n",
    "        transforms=datasets.default_valid_transforms,\n",
    "        task=task\n",
    "    )\n",
    "    print(f\"Starting evaluation on {task} with Mean-Teacher adaptation\")\n",
    "    CLASSES = dataset\n",
    "    NUM_CLASSES = len(CLASSES)\n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=collate_fn)\n",
    "    dataloader.valid_len = math.ceil(len(dataset)/4)\n",
    "\n",
    "    # Reset model to original state before each task\n",
    "    # model = load_original_model()  # You need to implement this function\n",
    "\n",
    "    # Setup Mean-Teacher\n",
    "    teacher_model = setup_mean_teacher_model(model)\n",
    "    optimizer = setup_optimizer_for_adaptation(model, lr=learning_rate)\n",
    "\n",
    "    print(f\"Teacher model created, optimizer setup with {len(optimizer.param_groups[0]['params']) if optimizer else 0} parameters\")\n",
    "\n",
    "    for batch_idx, batch in enumerate(tqdm(dataloader, total=dataloader.valid_len, desc=f\"Adapting {task}\")):\n",
    "\n",
    "        # Step 1: Get teacher predictions for pseudo-labeling\n",
    "        teacher_model.eval()\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(batch)\n",
    "\n",
    "        # Step 2: Generate pseudo labels\n",
    "        pseudo_inputs = set_pseudo_labels(batch, teacher_outputs, conf_th=conf_threshold)\n",
    "\n",
    "        # Step 3: Train student model with pseudo labels\n",
    "        if len(pseudo_inputs) > 0 and optimizer is not None:\n",
    "            model.train()\n",
    "            if hasattr(model, 'proposal_generator'):\n",
    "                model.proposal_generator.training = True\n",
    "            if hasattr(model, 'roi_heads'):\n",
    "                model.roi_heads.training = True\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            try:\n",
    "                # Forward pass with pseudo labels\n",
    "                losses = model(pseudo_inputs)\n",
    "\n",
    "                if isinstance(losses, dict):\n",
    "                    total_loss = sum(losses.values())\n",
    "                else:\n",
    "                    total_loss = losses\n",
    "\n",
    "                if total_loss > 0:\n",
    "                    total_loss.backward()\n",
    "\n",
    "                    # Gradient clipping (optional)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Step 4: Update teacher with EMA\n",
    "                    update_teacher_with_ema(teacher_model, model, ema_beta)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Training step failed at batch {batch_idx}: {e}\")\n",
    "\n",
    "        # Step 5: Get final predictions for evaluation (use teacher)\n",
    "        teacher_model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = teacher_model(batch)\n",
    "\n",
    "        # Process outputs for mAP calculation\n",
    "        for i, (output, input_data) in enumerate(zip(outputs, batch)):\n",
    "            instances = output['instances']\n",
    "            mask = instances.scores > threshold\n",
    "\n",
    "            pred_detection = Detections(xyxy=instances.pred_boxes.tensor[mask].detach().cpu().numpy(), \n",
    "                                        class_id=instances.pred_classes[mask].detach().cpu().numpy(),\n",
    "                                        confidence=instances.scores[mask].detach().cpu().numpy()\n",
    "                                        )\n",
    "            gt_instances = input_data['instances']\n",
    "            target_detection = Detections(\n",
    "                xyxy=gt_instances.gt_boxes.tensor.detach().cpu().numpy(),\n",
    "                class_id=gt_instances.gt_classes.detach().cpu().numpy()\n",
    "                )\n",
    "\n",
    "            predictions_list.append(pred_detection)\n",
    "            targets_list.append(target_detection)\n",
    "\n",
    "    # Compute mAP\n",
    "    map_metric.update(predictions=predictions_list, targets=targets_list)\n",
    "    print(f\"Computing mAP for {task}\")\n",
    "    m_ap = map_metric.compute()\n",
    "\n",
    "    per_class_map = {\n",
    "        f\"{CLASSES[idx]}_mAP@0.50:0.95\": m_ap.ap_per_class[idx].mean().item()\n",
    "        for idx in m_ap.matched_classes\n",
    "    }\n",
    "\n",
    "    print(f\"Results for {task} with Mean-Teacher:\")\n",
    "    print({\n",
    "        \"mAP@0.50:0.95\": m_ap.map50_95.item(),\n",
    "        \"mAP@0.50\": m_ap.map50.item(),\n",
    "        \"mAP@0.75\": m_ap.map75.item(),\n",
    "        **per_class_map,\n",
    "    })\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PTTA (P100 Compatible)",
   "language": "python",
   "name": "ptta-p100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
