{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/elicer/ptta\") # os.chdir(\"/home/ubuntu/test-time-adapters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20689e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA Device Number\n",
    "DEVICE_NUM = 0\n",
    "\n",
    "from os import environ\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = str(DEVICE_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dbcee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import path, environ\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "\n",
    "from ttadapters import datasets, models\n",
    "from ttadapters.models.base import ModelProvider\n",
    "from ttadapters.utils import visualizer, validator\n",
    "from ttadapters.datasets import DatasetHolder, scenarios\n",
    "\n",
    "from ttadapters.methods.other_method.baseline import ActMADConfig, ActMAD, NORMConfig, NORM, DUAConfig, DUA, MeanTeacherConfig, MeanTeacher, WHWConfig, WHW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fff8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "environ[\"TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS\"] = \"1\"\n",
    "environ[\"TORCHDYNAMO_CAPTURE_DYNAMIC_OUTPUT_SHAPE_OPS\"] = \"1\"\n",
    "\n",
    "torch._dynamo.config.capture_scalar_outputs = True\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a41bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Batch Size\n",
    "BATCH_SIZE = 2, 8, 4  # Local\n",
    "#BATCH_SIZE = 40, 200, 1  # A100 or H100\n",
    "ACCUMULATE_STEPS = 1\n",
    "\n",
    "# Set Data Root\n",
    "DATA_ROOT = path.join(\".\", \"data\")\n",
    "\n",
    "# Set Target Dataset\n",
    "SOURCE_DOMAIN = datasets.SHIFTDataset\n",
    "\n",
    "# Set Run Mode\n",
    "TEST_MODE = True\n",
    "\n",
    "# Set Model List\n",
    "MODEL_ZOO = [\"rcnn\", \"swinrcnn\", \"yolo11\", \"rtdetr\"]\n",
    "MODEL_TYPE = MODEL_ZOO[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA Device Number\n",
    "DEVICE_NUM = 0\n",
    "ADDITIONAL_GPU = 0\n",
    "DATA_TYPE = torch.float32\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if ADDITIONAL_GPU:\n",
    "        torch.cuda.set_device(DEVICE_NUM)\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{DEVICE_NUM}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DEVICE_NUM = -1\n",
    "\n",
    "print(f\"INFO: Using device - {device}\" + (f\":{DEVICE_NUM}\" if ADDITIONAL_GPU else \"\"))\n",
    "print(f\"INFO: Using data precision - {DATA_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b6afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast download patch\n",
    "datasets.patch_fast_download_for_object_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6adcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic pre-training dataset\n",
    "match SOURCE_DOMAIN:\n",
    "    case datasets.SHIFTDataset:\n",
    "        dataset = DatasetHolder(\n",
    "            train=datasets.SHIFTClearDatasetForObjectDetection(root=DATA_ROOT, train=True),\n",
    "            valid=datasets.SHIFTClearDatasetForObjectDetection(root=DATA_ROOT, valid=True),\n",
    "            test=datasets.SHIFTCorruptedDatasetForObjectDetection(root=DATA_ROOT, valid=True)\n",
    "        )\n",
    "    case datasets.CityscapesDataset:\n",
    "        pass\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported dataset: {SOURCE_DOMAIN}\")\n",
    "\n",
    "# Dataset info\n",
    "CLASSES = dataset.train.classes\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "print(f\"INFO: Number of classes - {NUM_CLASSES} {CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d937b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "match MODEL_TYPE:\n",
    "    case \"rcnn\":\n",
    "        model = models.FasterRCNNForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = model.load_from(**vars(model.Weights.SHIFT_CLEAR_NATUREYOO if TEST_MODE else model.Weights.IMAGENET_OFFICIAL), strict=False)\n",
    "    case \"swinrcnn\":\n",
    "        model = models.SwinRCNNForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = model.load_from(**vars(model.Weights.SHIFT_CLEAR_NATUREYOO if TEST_MODE else model.Weights.IMAGENET_XIAOHU2015), strict=False)\n",
    "    case \"rtdetr\":\n",
    "        model = models.RTDetrForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = model.load_from(**vars(model.Weights.SHIFT_CLEAR if TEST_MODE else model.Weights.COCO_OFFICIAL), strict=False)\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported model type: {MODEL_TYPE}\")\n",
    "\n",
    "print(\"INFO: Model state loaded -\", load_result)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54637dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ActMADConfig()\n",
    "config.data_root = DATA_ROOT\n",
    "config.lr = 0.0001\n",
    "config.clear_dataset = model.DataPreparation(dataset.train, evaluation_mode=True)\n",
    "adaptive_model = ActMAD(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b535f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = NORMConfig()\n",
    "config.data_root = DATA_ROOT\n",
    "adaptive_model = NORM(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b4bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DUAConfig()\n",
    "config.data_root = DATA_ROOT\n",
    "adaptive_model = DUA(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbe063",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = MeanTeacherConfig()\n",
    "config.data_root = DATA_ROOT\n",
    "config.lr = 0.0001\n",
    "adaptive_model = MeanTeacher(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd9b583",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = WHWConfig()\n",
    "config.data_root = DATA_ROOT\n",
    "config.lr = 0.0001\n",
    "config.clear_dataset = model.DataPreparation(dataset.train, evaluation_mode=True)\n",
    "adaptive_model = WHW(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93fffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compile model\n",
    "# adaptive_model = torch.compile(adaptive_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b429cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure split (required due to Scenario class works with coroutines)\n",
    "_ = datasets.SHIFTContinuousSubsetForObjectDetection(root=DATA_ROOT, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92525ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preparation = model.DataPreparation(datasets.base.BaseDataset(), evaluation_mode=True)\n",
    "\n",
    "discrete_scenario = scenarios.SHIFTDiscreteScenario(\n",
    "    root=DATA_ROOT, valid=True, order=scenarios.SHIFTDiscreteScenario.WHWPAPER, transforms=data_preparation.transforms\n",
    ")\n",
    "continuous_scenario = scenarios.SHIFTContinuousScenario(\n",
    "    root=DATA_ROOT, valid=True, order=scenarios.SHIFTContinuousScenario.DEFAULT, transforms=data_preparation.transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = validator.DetectionEvaluator(adaptive_model, no_grad=False, classes=CLASSES, data_preparation=data_preparation, dtype=DATA_TYPE, device=device)\n",
    "evaluator_loader_params = dict(batch_size=BATCH_SIZE[2], shuffle=False, collate_fn=data_preparation.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3885c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_model.model_provider = model.model_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71425298",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.visualize_metrics(discrete_scenario(**evaluator_loader_params).play(evaluator, index=[adaptive_model.__class__.__name__]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc81d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.visualize_metrics(continuous_scenario(**evaluator_loader_params).play(evaluator, index=[adaptive_model.__class__.__name__]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PTTA Environment",
   "language": "python",
   "name": "ptta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
