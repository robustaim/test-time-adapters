{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/elicer/ptta\") # os.chdir(\"/home/ubuntu/test-time-adapters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20689e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA Device Number\n",
    "DEVICE_NUM = 0\n",
    "\n",
    "from os import environ\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = str(DEVICE_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dbcee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from os import path, environ\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "\n",
    "from ttadapters import datasets, models\n",
    "from ttadapters.models.base import ModelProvider\n",
    "from ttadapters.utils import visualizer, validator\n",
    "from ttadapters.datasets import DatasetHolder, scenarios\n",
    "\n",
    "from ttadapters.methods.other_method.baseline import ActMADConfig, ActMAD, NORMConfig, NORM, DUAConfig, DUA, MeanTeacherConfig, MeanTeacher, WHWConfig, WHW\n",
    "from ttadapters.methods.other_method.our_method import Ours, OursConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fff8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "environ[\"TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS\"] = \"1\"\n",
    "environ[\"TORCHDYNAMO_CAPTURE_DYNAMIC_OUTPUT_SHAPE_OPS\"] = \"1\"\n",
    "\n",
    "torch._dynamo.config.capture_scalar_outputs = True\n",
    "torch._dynamo.config.suppress_errors = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a41bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Batch Size\n",
    "BATCH_SIZE = 2, 8, 1  # Local\n",
    "#BATCH_SIZE = 40, 200, 1  # A100 or H100\n",
    "ACCUMULATE_STEPS = 1\n",
    "\n",
    "# Set Data Root\n",
    "DATA_ROOT = path.join(\".\", \"data\")\n",
    "\n",
    "# Set Target Dataset\n",
    "SOURCE_DOMAIN = datasets.SHIFTDataset\n",
    "\n",
    "# Set Run Mode\n",
    "TEST_MODE = True\n",
    "\n",
    "# Set Model List\n",
    "MODEL_ZOO = [\"rcnn\", \"swinrcnn\", \"yolo11\", \"rtdetr\"]\n",
    "MODEL_TYPE = MODEL_ZOO[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0d17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDA Device Number\n",
    "DEVICE_NUM = 0\n",
    "ADDITIONAL_GPU = 0\n",
    "DATA_TYPE = torch.float32\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if ADDITIONAL_GPU:\n",
    "        torch.cuda.set_device(DEVICE_NUM)\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(f\"cuda:{DEVICE_NUM}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    DEVICE_NUM = -1\n",
    "\n",
    "print(f\"INFO: Using device - {device}\" + (f\":{DEVICE_NUM}\" if ADDITIONAL_GPU else \"\"))\n",
    "print(f\"INFO: Using data precision - {DATA_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b6afc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast download patch\n",
    "datasets.patch_fast_download_for_object_detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6adcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic pre-training dataset\n",
    "match SOURCE_DOMAIN:\n",
    "    case datasets.SHIFTDataset:\n",
    "        dataset = DatasetHolder(\n",
    "            train=datasets.SHIFTClearDatasetForObjectDetection(root=DATA_ROOT, train=True),\n",
    "            valid=datasets.SHIFTClearDatasetForObjectDetection(root=DATA_ROOT, valid=True),\n",
    "            test=datasets.SHIFTCorruptedDatasetForObjectDetection(root=DATA_ROOT, valid=True)\n",
    "        )\n",
    "    case datasets.CityscapesDataset:\n",
    "        pass\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported dataset: {SOURCE_DOMAIN}\")\n",
    "\n",
    "# Dataset info\n",
    "CLASSES = dataset.train.classes\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "print(f\"INFO: Number of classes - {NUM_CLASSES} {CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d937b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "match MODEL_TYPE:\n",
    "    case \"rcnn\":\n",
    "        model = models.FasterRCNNForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = model.load_from(**vars(model.Weights.SHIFT_CLEAR_NATUREYOO if TEST_MODE else model.Weights.IMAGENET_OFFICIAL), strict=False)\n",
    "    case \"swinrcnn\":\n",
    "        model = models.SwinRCNNForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = model.load_from(**vars(model.Weights.SHIFT_CLEAR_NATUREYOO if TEST_MODE else model.Weights.IMAGENET_XIAOHU2015), strict=False)\n",
    "    case \"rtdetr\":\n",
    "        model = models.RTDetrForObjectDetection(dataset=SOURCE_DOMAIN)\n",
    "        load_result = model.load_from(**vars(model.Weights.SHIFT_CLEAR if TEST_MODE else model.Weights.COCO_OFFICIAL), strict=False)\n",
    "    case _:\n",
    "        raise ValueError(f\"Unsupported model type: {MODEL_TYPE}\")\n",
    "\n",
    "print(\"INFO: Model state loaded -\", load_result)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0f406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = OursConfig(\n",
    "#     # ============ Model & Device ============\n",
    "#     model_type=\"rcnn\",\n",
    "#     data_root='./data',\n",
    "#     device=torch.device(\"cuda\"),\n",
    "#     batch_size=1,  # Must be 1 for tracking\n",
    "\n",
    "#     # ============ Adaptation Layers ============\n",
    "#     adapt_bn=True,     # ✅ BN/LayerNorm 학습\n",
    "#     adapt_conv=False,  # Conv는 BN만으로 충분\n",
    "#     adapt_linear=False,\n",
    "\n",
    "#     # ============ Optimizer ============\n",
    "#     optimizer_option=\"AdamW\",\n",
    "#     lr=1e-4,  # ⬆️ 1e-6 → 1e-5로 상향 (delta loss가 강해서 안정적)\n",
    "#     momentum=0.9,\n",
    "#     weight_decay=1e-4,\n",
    "\n",
    "#     # ============ Tracking Parameters ============\n",
    "#     iou_threshold=0.3,\n",
    "#     min_confidence=0.5,\n",
    "#     max_age=30,\n",
    "\n",
    "#     # ============ Loss Settings ============\n",
    "#     bbox_loss_weight=1.0,\n",
    "#     smooth_l1_beta=1.0,\n",
    "#     use_delta_loss=True,  # ✅ NEW: Delta encoding 사용 (BN에 효과적)\n",
    "\n",
    "#     # ============ Kalman Update Strategy ============\n",
    "#     use_model_for_kalman_update=True,  # ✅ CHANGED: True로 (detection 사용)\n",
    "#     kalman_detection_blend=1.0,  # ✅ CHANGED: 1.0 (pure detection)\n",
    "\n",
    "#     # ============ Batch Accumulation ============\n",
    "#     batch_accumulation_steps=4,  # ✅ NEW: 4 프레임 누적 (gradient 안정화)\n",
    "\n",
    "#     # ============ Innovation Weighting ============\n",
    "#     use_covariance_weighting=False,\n",
    "#     use_innovation_weighting=True,\n",
    "#     max_innovation=100.0,\n",
    "#     min_innovation_weight=0.2,\n",
    "\n",
    "#     # ============ Detection Confidence Gating ============\n",
    "#     confidence_penalty_exponent=2.0,\n",
    "\n",
    "#     # ============ Scene Change Detection ============\n",
    "#     shift_detection_window=10,\n",
    "#     shift_detection_threshold=0.3,\n",
    "#     shift_detection_min_matches=2,\n",
    "#     reset_tracker_on_shift=False,\n",
    "\n",
    "#     # ============ Quality Filter ============\n",
    "#     enable_quality_filter=True,\n",
    "#     min_matches=4,  # ✅ CHANGED: 2 → 4 (더 안정적)\n",
    "\n",
    "#     min_track_hits=2.0,  # 3.0 → 2.0 (약간 완화)\n",
    "#     min_match_iou=0.5,\n",
    "#     max_innovation_cv=0.8,\n",
    "#     min_avg_innovation=5.0,\n",
    "#     max_avg_innovation=80.0,\n",
    "#     max_outlier_ratio=3.0,\n",
    "# )\n",
    "\n",
    "# adaptive_model = Ours(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54637dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = ActMADConfig()\n",
    "# config.data_root = DATA_ROOT\n",
    "# config.lr = 0.00001\n",
    "# config.clear_dataset = model.DataPreparation(dataset.train, evaluation_mode=True)\n",
    "# adaptive_model = ActMAD(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b535f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = NORMConfig()\n",
    "# config.data_root = DATA_ROOT\n",
    "# adaptive_model = NORM(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b4bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = DUAConfig()\n",
    "# config.data_root = DATA_ROOT\n",
    "# adaptive_model = DUA(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dbe063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = MeanTeacherConfig()\n",
    "# config.data_root = DATA_ROOT\n",
    "# config.lr = 0.0001\n",
    "# adaptive_model = MeanTeacher(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ee603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # skip x\n",
    "# config = WHWConfig()\n",
    "# config.model_type = \"rcnn\"\n",
    "# config.data_root = \"./data\"\n",
    "# config.device = torch.device(\"cuda:0\")\n",
    "\n",
    "# # Optimizer\n",
    "# config.lr = 2e-3\n",
    "# config.optimizer_option = \"SGD\"\n",
    "# config.momentum = 0.9\n",
    "# config.weight_decay = 1e-4\n",
    "\n",
    "# # Adaptation\n",
    "# config.adaptation_where = \"adapter\"\n",
    "# config.adapter_bottleneck_ratio = 24 # [16, 24, 32]\n",
    "\n",
    "# # Skip settings\n",
    "# config.skip_redundant = None # \"stat+period+ema\"\n",
    "# config.skip_beta = 1.05      # SKIP_BETA\n",
    "# config.skip_period = 10      # SKIP_PERIOD\n",
    "# config.skip_tau = 1.1        # SKIP_TAU\n",
    "\n",
    "# # Loss settings\n",
    "# config.fg_align = \"KL\"\n",
    "# config.gl_align = \"KL\"\n",
    "# config.alpha_fg = 1.0\n",
    "# config.alpha_gl = 0.5 # original : 1.0\n",
    "# config.ema_gamma = 128 # [64, 96, 128]\n",
    "# config.freq_weight = True\n",
    "\n",
    "# # Dataset\n",
    "# config.num_classes = 6\n",
    "# config.clear_dataset = model.DataPreparation(dataset.train, evaluation_mode=True)\n",
    "# config.clear_statistics_batch = 64\n",
    "# config.output_path = \"./whw_source_statistics_clear.pt\"\n",
    "\n",
    "# adaptive_model = WHW(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a74a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip o\n",
    "config = WHWConfig()\n",
    "config.model_type = \"rcnn\"\n",
    "config.data_root = \"./data\"\n",
    "config.device = torch.device(\"cuda:0\")\n",
    "\n",
    "# Optimizer\n",
    "config.lr = 2e-3\n",
    "config.optimizer_option = \"SGD\"\n",
    "config.momentum = 0.9\n",
    "config.weight_decay = 1e-4\n",
    "\n",
    "# Adaptation\n",
    "config.adaptation_where = \"adapter\"\n",
    "config.adapter_bottleneck_ratio = 24 # [16, 24, 32]\n",
    "\n",
    "# Skip settings\n",
    "config.skip_redundant = \"stat+period+ema\" # \"stat+period+ema\"\n",
    "config.skip_beta = 1.05      # SKIP_BETA\n",
    "config.skip_period = 10      # SKIP_PERIOD\n",
    "config.skip_tau = 1.1        # SKIP_TAU\n",
    "\n",
    "# Loss settings\n",
    "config.fg_align = \"KL\"\n",
    "config.gl_align = \"KL\"\n",
    "config.alpha_fg = 1.0\n",
    "config.alpha_gl = 0.5 # original : 1.0\n",
    "config.ema_gamma = 128 # [64, 96, 128]\n",
    "config.freq_weight = True\n",
    "\n",
    "# Dataset\n",
    "config.num_classes = 6\n",
    "config.clear_dataset = model.DataPreparation(dataset.train, evaluation_mode=True)\n",
    "config.clear_statistics_batch = 64\n",
    "config.output_path = \"./whw_source_statistics_clear.pt\"\n",
    "\n",
    "adaptive_model = WHW(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93fffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compile model\n",
    "# adaptive_model = torch.compile(adaptive_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b429cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure split (required due to Scenario class works with coroutines)\n",
    "_ = datasets.SHIFTContinuousSubsetForObjectDetection(root=DATA_ROOT, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92525ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preparation = model.DataPreparation(datasets.base.BaseDataset(), evaluation_mode=True)\n",
    "\n",
    "discrete_scenario = scenarios.SHIFTDiscreteScenario(\n",
    "    root=DATA_ROOT, valid=True, order=scenarios.SHIFTDiscreteScenario.WHWPAPER, transforms=data_preparation.transforms\n",
    ")\n",
    "continuous_scenario = scenarios.SHIFTContinuousScenario(\n",
    "    root=DATA_ROOT, valid=True, order=scenarios.SHIFTContinuousScenario.DEFAULT, transforms=data_preparation.transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = validator.DetectionEvaluator(adaptive_model, no_grad=False, classes=CLASSES, data_preparation=data_preparation, dtype=DATA_TYPE, device=device)\n",
    "evaluator_loader_params = dict(batch_size=BATCH_SIZE[2], shuffle=False, collate_fn=data_preparation.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3885c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_model.model_provider = model.model_provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "visualizer.visualize_metrics(continuous_scenario(**evaluator_loader_params).play(evaluator, index=[adaptive_model.__class__.__name__]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "visualizer.visualize_metrics(continuous_scenario(**evaluator_loader_params).play(evaluator, index=[adaptive_model.__class__.__name__]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d664b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "visualizer.visualize_metrics(continuous_scenario(**evaluator_loader_params).play(evaluator, index=[adaptive_model.__class__.__name__]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d5c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "visualizer.visualize_metrics(continuous_scenario(**evaluator_loader_params).play(evaluator, index=[adaptive_model.__class__.__name__]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab54b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "visualizer.visualize_metrics(continuous_scenario(**evaluator_loader_params).play(evaluator, index=[adaptive_model.__class__.__name__]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207cc229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "visualizer.visualize_metrics(continuous_scenario(**evaluator_loader_params).play(evaluator, index=[adaptive_model.__class__.__name__]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89c7fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7\n",
    "visualizer.visualize_metrics(continuous_scenario(**evaluator_loader_params).play(evaluator, index=[adaptive_model.__class__.__name__]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8bcaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8\n",
    "visualizer.visualize_metrics(continuous_scenario(**evaluator_loader_params).play(evaluator, index=[adaptive_model.__class__.__name__]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2378656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9\n",
    "visualizer.visualize_metrics(continuous_scenario(**evaluator_loader_params).play(evaluator, index=[adaptive_model.__class__.__name__]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd76257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10\n",
    "visualizer.visualize_metrics(continuous_scenario(**evaluator_loader_params).play(evaluator, index=[adaptive_model.__class__.__name__]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a51d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer.visualize_metrics(continuous_scenario(**evaluator_loader_params).play(evaluator, index=[adaptive_model.__class__.__name__]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttadapters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
